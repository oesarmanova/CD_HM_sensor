{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CD_HM_2D_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fb04b5ab63e74d3d96e4bafd316788ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_63fd438dd6414d1ca93e7a9f417332fc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5da8e89b6a044f8a845737ff7b276b90",
              "IPY_MODEL_ce449197d2c84a26ad6b645b0fcb02e1"
            ]
          }
        },
        "63fd438dd6414d1ca93e7a9f417332fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5da8e89b6a044f8a845737ff7b276b90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_6f6229b3b7344ccaaf7f8ac687db67fe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7b5ed3a32f624da0b54e02b273d7995f"
          }
        },
        "ce449197d2c84a26ad6b645b0fcb02e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3d1ca0d8f03943599cdde92da03d1fa7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6d01414d04b9479d9635c40a9f351b7c"
          }
        },
        "6f6229b3b7344ccaaf7f8ac687db67fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7b5ed3a32f624da0b54e02b273d7995f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d1ca0d8f03943599cdde92da03d1fa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6d01414d04b9479d9635c40a9f351b7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ec7a4b3f8474edf9dc0966ab9837ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1f575fdfe1614b3c8e5d1da28a883f42",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_74592891670f458ba6efd1b655e2533d",
              "IPY_MODEL_b7f733c3dc5b49c7aa12e3db4e43bef5"
            ]
          }
        },
        "1f575fdfe1614b3c8e5d1da28a883f42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "74592891670f458ba6efd1b655e2533d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_aac3a618663240a2a38b01f689e0166d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d47268abe5634063aeb96ec93acde2ca"
          }
        },
        "b7f733c3dc5b49c7aa12e3db4e43bef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cbb30d3fcc234cc8b043ed12f5c5341f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0f97127eff284ce89b0f0490f1ac3b09"
          }
        },
        "aac3a618663240a2a38b01f689e0166d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d47268abe5634063aeb96ec93acde2ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cbb30d3fcc234cc8b043ed12f5c5341f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0f97127eff284ce89b0f0490f1ac3b09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhzIgm1rXguU"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import median_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.model_selection import KFold\n",
        "import random\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3qIIZJSbFYs"
      },
      "source": [
        "Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjzoexVNXkF6",
        "outputId": "f2c01196-0356-42a1-95c4-3a0026cf472b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXjuhwjaXugD",
        "outputId": "71a60b1e-55d5-46af-d522-32f3d75d8351"
      },
      "source": [
        "!unzip drive/My\\ Drive/NN_201_Sarmanova/full_data.zip #full_data.zip located in NN_201_Sarmanova folder at google drive."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  drive/My Drive/NN_201_Sarmanova/full_data.zip\n",
            "  inflating: full_data/1.csv         \n",
            "  inflating: full_data/10.csv        \n",
            "  inflating: full_data/100.csv       \n",
            "  inflating: full_data/1000.csv      \n",
            "  inflating: full_data/101.csv       \n",
            "  inflating: full_data/102.csv       \n",
            "  inflating: full_data/103.csv       \n",
            "  inflating: full_data/104.csv       \n",
            "  inflating: full_data/105.csv       \n",
            "  inflating: full_data/106.csv       \n",
            "  inflating: full_data/107.csv       \n",
            "  inflating: full_data/108.csv       \n",
            "  inflating: full_data/109.csv       \n",
            "  inflating: full_data/11.csv        \n",
            "  inflating: full_data/110.csv       \n",
            "  inflating: full_data/111.csv       \n",
            "  inflating: full_data/112.csv       \n",
            "  inflating: full_data/113.csv       \n",
            "  inflating: full_data/114.csv       \n",
            "  inflating: full_data/115.csv       \n",
            "  inflating: full_data/116.csv       \n",
            "  inflating: full_data/117.csv       \n",
            "  inflating: full_data/118.csv       \n",
            "  inflating: full_data/119.csv       \n",
            "  inflating: full_data/12.csv        \n",
            "  inflating: full_data/120.csv       \n",
            "  inflating: full_data/121.csv       \n",
            "  inflating: full_data/122.csv       \n",
            "  inflating: full_data/123.csv       \n",
            "  inflating: full_data/124.csv       \n",
            "  inflating: full_data/125.csv       \n",
            "  inflating: full_data/126.csv       \n",
            "  inflating: full_data/127.csv       \n",
            "  inflating: full_data/128.csv       \n",
            "  inflating: full_data/129.csv       \n",
            "  inflating: full_data/13.csv        \n",
            "  inflating: full_data/130.csv       \n",
            "  inflating: full_data/131.csv       \n",
            "  inflating: full_data/132.csv       \n",
            "  inflating: full_data/133.csv       \n",
            "  inflating: full_data/134.csv       \n",
            "  inflating: full_data/135.csv       \n",
            "  inflating: full_data/136.csv       \n",
            "  inflating: full_data/137.csv       \n",
            "  inflating: full_data/138.csv       \n",
            "  inflating: full_data/139.csv       \n",
            "  inflating: full_data/14.csv        \n",
            "  inflating: full_data/140.csv       \n",
            "  inflating: full_data/141.csv       \n",
            "  inflating: full_data/142.csv       \n",
            "  inflating: full_data/143.csv       \n",
            "  inflating: full_data/144.csv       \n",
            "  inflating: full_data/145.csv       \n",
            "  inflating: full_data/146.csv       \n",
            "  inflating: full_data/147.csv       \n",
            "  inflating: full_data/148.csv       \n",
            "  inflating: full_data/149.csv       \n",
            "  inflating: full_data/15.csv        \n",
            "  inflating: full_data/150.csv       \n",
            "  inflating: full_data/151.csv       \n",
            "  inflating: full_data/152.csv       \n",
            "  inflating: full_data/153.csv       \n",
            "  inflating: full_data/154.csv       \n",
            "  inflating: full_data/155.csv       \n",
            "  inflating: full_data/156.csv       \n",
            "  inflating: full_data/157.csv       \n",
            "  inflating: full_data/158.csv       \n",
            "  inflating: full_data/159.csv       \n",
            "  inflating: full_data/16.csv        \n",
            "  inflating: full_data/160.csv       \n",
            "  inflating: full_data/161.csv       \n",
            "  inflating: full_data/162.csv       \n",
            "  inflating: full_data/163.csv       \n",
            "  inflating: full_data/164.csv       \n",
            "  inflating: full_data/165.csv       \n",
            "  inflating: full_data/166.csv       \n",
            "  inflating: full_data/167.csv       \n",
            "  inflating: full_data/168.csv       \n",
            "  inflating: full_data/169.csv       \n",
            "  inflating: full_data/17.csv        \n",
            "  inflating: full_data/170.csv       \n",
            "  inflating: full_data/171.csv       \n",
            "  inflating: full_data/172.csv       \n",
            "  inflating: full_data/173.csv       \n",
            "  inflating: full_data/174.csv       \n",
            "  inflating: full_data/175.csv       \n",
            "  inflating: full_data/176.csv       \n",
            "  inflating: full_data/177.csv       \n",
            "  inflating: full_data/178.csv       \n",
            "  inflating: full_data/179.csv       \n",
            "  inflating: full_data/18.csv        \n",
            "  inflating: full_data/180.csv       \n",
            "  inflating: full_data/181.csv       \n",
            "  inflating: full_data/182.csv       \n",
            "  inflating: full_data/183.csv       \n",
            "  inflating: full_data/184.csv       \n",
            "  inflating: full_data/185.csv       \n",
            "  inflating: full_data/186.csv       \n",
            "  inflating: full_data/187.csv       \n",
            "  inflating: full_data/188.csv       \n",
            "  inflating: full_data/189.csv       \n",
            "  inflating: full_data/19.csv        \n",
            "  inflating: full_data/190.csv       \n",
            "  inflating: full_data/191.csv       \n",
            "  inflating: full_data/192.csv       \n",
            "  inflating: full_data/193.csv       \n",
            "  inflating: full_data/194.csv       \n",
            "  inflating: full_data/195.csv       \n",
            "  inflating: full_data/196.csv       \n",
            "  inflating: full_data/197.csv       \n",
            "  inflating: full_data/198.csv       \n",
            "  inflating: full_data/199.csv       \n",
            "  inflating: full_data/2.csv         \n",
            "  inflating: full_data/20.csv        \n",
            "  inflating: full_data/200.csv       \n",
            "  inflating: full_data/201.csv       \n",
            "  inflating: full_data/202.csv       \n",
            "  inflating: full_data/203.csv       \n",
            "  inflating: full_data/204.csv       \n",
            "  inflating: full_data/205.csv       \n",
            "  inflating: full_data/206.csv       \n",
            "  inflating: full_data/207.csv       \n",
            "  inflating: full_data/208.csv       \n",
            "  inflating: full_data/209.csv       \n",
            "  inflating: full_data/21.csv        \n",
            "  inflating: full_data/210.csv       \n",
            "  inflating: full_data/211.csv       \n",
            "  inflating: full_data/212.csv       \n",
            "  inflating: full_data/213.csv       \n",
            "  inflating: full_data/214.csv       \n",
            "  inflating: full_data/215.csv       \n",
            "  inflating: full_data/216.csv       \n",
            "  inflating: full_data/217.csv       \n",
            "  inflating: full_data/218.csv       \n",
            "  inflating: full_data/219.csv       \n",
            "  inflating: full_data/22.csv        \n",
            "  inflating: full_data/220.csv       \n",
            "  inflating: full_data/221.csv       \n",
            "  inflating: full_data/222.csv       \n",
            "  inflating: full_data/223.csv       \n",
            "  inflating: full_data/224.csv       \n",
            "  inflating: full_data/225.csv       \n",
            "  inflating: full_data/226.csv       \n",
            "  inflating: full_data/227.csv       \n",
            "  inflating: full_data/228.csv       \n",
            "  inflating: full_data/229.csv       \n",
            "  inflating: full_data/23.csv        \n",
            "  inflating: full_data/230.csv       \n",
            "  inflating: full_data/231.csv       \n",
            "  inflating: full_data/232.csv       \n",
            "  inflating: full_data/233.csv       \n",
            "  inflating: full_data/234.csv       \n",
            "  inflating: full_data/235.csv       \n",
            "  inflating: full_data/236.csv       \n",
            "  inflating: full_data/237.csv       \n",
            "  inflating: full_data/238.csv       \n",
            "  inflating: full_data/239.csv       \n",
            "  inflating: full_data/24.csv        \n",
            "  inflating: full_data/240.csv       \n",
            "  inflating: full_data/241.csv       \n",
            "  inflating: full_data/242.csv       \n",
            "  inflating: full_data/243.csv       \n",
            "  inflating: full_data/244.csv       \n",
            "  inflating: full_data/245.csv       \n",
            "  inflating: full_data/246.csv       \n",
            "  inflating: full_data/247.csv       \n",
            "  inflating: full_data/248.csv       \n",
            "  inflating: full_data/249.csv       \n",
            "  inflating: full_data/25.csv        \n",
            "  inflating: full_data/250.csv       \n",
            "  inflating: full_data/251.csv       \n",
            "  inflating: full_data/252.csv       \n",
            "  inflating: full_data/253.csv       \n",
            "  inflating: full_data/254.csv       \n",
            "  inflating: full_data/255.csv       \n",
            "  inflating: full_data/256.csv       \n",
            "  inflating: full_data/257.csv       \n",
            "  inflating: full_data/258.csv       \n",
            "  inflating: full_data/259.csv       \n",
            "  inflating: full_data/26.csv        \n",
            "  inflating: full_data/260.csv       \n",
            "  inflating: full_data/261.csv       \n",
            "  inflating: full_data/262.csv       \n",
            "  inflating: full_data/263.csv       \n",
            "  inflating: full_data/264.csv       \n",
            "  inflating: full_data/265.csv       \n",
            "  inflating: full_data/266.csv       \n",
            "  inflating: full_data/267.csv       \n",
            "  inflating: full_data/268.csv       \n",
            "  inflating: full_data/269.csv       \n",
            "  inflating: full_data/27.csv        \n",
            "  inflating: full_data/270.csv       \n",
            "  inflating: full_data/271.csv       \n",
            "  inflating: full_data/272.csv       \n",
            "  inflating: full_data/273.csv       \n",
            "  inflating: full_data/274.csv       \n",
            "  inflating: full_data/275.csv       \n",
            "  inflating: full_data/276.csv       \n",
            "  inflating: full_data/277.csv       \n",
            "  inflating: full_data/278.csv       \n",
            "  inflating: full_data/279.csv       \n",
            "  inflating: full_data/28.csv        \n",
            "  inflating: full_data/280.csv       \n",
            "  inflating: full_data/281.csv       \n",
            "  inflating: full_data/282.csv       \n",
            "  inflating: full_data/283.csv       \n",
            "  inflating: full_data/284.csv       \n",
            "  inflating: full_data/285.csv       \n",
            "  inflating: full_data/286.csv       \n",
            "  inflating: full_data/287.csv       \n",
            "  inflating: full_data/288.csv       \n",
            "  inflating: full_data/289.csv       \n",
            "  inflating: full_data/29.csv        \n",
            "  inflating: full_data/290.csv       \n",
            "  inflating: full_data/291.csv       \n",
            "  inflating: full_data/292.csv       \n",
            "  inflating: full_data/293.csv       \n",
            "  inflating: full_data/294.csv       \n",
            "  inflating: full_data/295.csv       \n",
            "  inflating: full_data/296.csv       \n",
            "  inflating: full_data/297.csv       \n",
            "  inflating: full_data/298.csv       \n",
            "  inflating: full_data/299.csv       \n",
            "  inflating: full_data/3.csv         \n",
            "  inflating: full_data/30.csv        \n",
            "  inflating: full_data/300.csv       \n",
            "  inflating: full_data/301.csv       \n",
            "  inflating: full_data/302.csv       \n",
            "  inflating: full_data/303.csv       \n",
            "  inflating: full_data/304.csv       \n",
            "  inflating: full_data/305.csv       \n",
            "  inflating: full_data/306.csv       \n",
            "  inflating: full_data/307.csv       \n",
            "  inflating: full_data/308.csv       \n",
            "  inflating: full_data/309.csv       \n",
            "  inflating: full_data/31.csv        \n",
            "  inflating: full_data/310.csv       \n",
            "  inflating: full_data/311.csv       \n",
            "  inflating: full_data/312.csv       \n",
            "  inflating: full_data/313.csv       \n",
            "  inflating: full_data/314.csv       \n",
            "  inflating: full_data/315.csv       \n",
            "  inflating: full_data/316.csv       \n",
            "  inflating: full_data/317.csv       \n",
            "  inflating: full_data/318.csv       \n",
            "  inflating: full_data/319.csv       \n",
            "  inflating: full_data/32.csv        \n",
            "  inflating: full_data/320.csv       \n",
            "  inflating: full_data/321.csv       \n",
            "  inflating: full_data/322.csv       \n",
            "  inflating: full_data/323.csv       \n",
            "  inflating: full_data/324.csv       \n",
            "  inflating: full_data/325.csv       \n",
            "  inflating: full_data/326.csv       \n",
            "  inflating: full_data/327.csv       \n",
            "  inflating: full_data/328.csv       \n",
            "  inflating: full_data/329.csv       \n",
            "  inflating: full_data/33.csv        \n",
            "  inflating: full_data/330.csv       \n",
            "  inflating: full_data/331.csv       \n",
            "  inflating: full_data/332.csv       \n",
            "  inflating: full_data/333.csv       \n",
            "  inflating: full_data/334.csv       \n",
            "  inflating: full_data/335.csv       \n",
            "  inflating: full_data/336.csv       \n",
            "  inflating: full_data/337.csv       \n",
            "  inflating: full_data/338.csv       \n",
            "  inflating: full_data/339.csv       \n",
            "  inflating: full_data/34.csv        \n",
            "  inflating: full_data/340.csv       \n",
            "  inflating: full_data/341.csv       \n",
            "  inflating: full_data/342.csv       \n",
            "  inflating: full_data/343.csv       \n",
            "  inflating: full_data/344.csv       \n",
            "  inflating: full_data/345.csv       \n",
            "  inflating: full_data/346.csv       \n",
            "  inflating: full_data/347.csv       \n",
            "  inflating: full_data/348.csv       \n",
            "  inflating: full_data/349.csv       \n",
            "  inflating: full_data/35.csv        \n",
            "  inflating: full_data/350.csv       \n",
            "  inflating: full_data/351.csv       \n",
            "  inflating: full_data/352.csv       \n",
            "  inflating: full_data/353.csv       \n",
            "  inflating: full_data/354.csv       \n",
            "  inflating: full_data/355.csv       \n",
            "  inflating: full_data/356.csv       \n",
            "  inflating: full_data/357.csv       \n",
            "  inflating: full_data/358.csv       \n",
            "  inflating: full_data/359.csv       \n",
            "  inflating: full_data/36.csv        \n",
            "  inflating: full_data/360.csv       \n",
            "  inflating: full_data/361.csv       \n",
            "  inflating: full_data/362.csv       \n",
            "  inflating: full_data/363.csv       \n",
            "  inflating: full_data/364.csv       \n",
            "  inflating: full_data/365.csv       \n",
            "  inflating: full_data/366.csv       \n",
            "  inflating: full_data/367.csv       \n",
            "  inflating: full_data/368.csv       \n",
            "  inflating: full_data/369.csv       \n",
            "  inflating: full_data/37.csv        \n",
            "  inflating: full_data/370.csv       \n",
            "  inflating: full_data/371.csv       \n",
            "  inflating: full_data/372.csv       \n",
            "  inflating: full_data/373.csv       \n",
            "  inflating: full_data/374.csv       \n",
            "  inflating: full_data/375.csv       \n",
            "  inflating: full_data/376.csv       \n",
            "  inflating: full_data/377.csv       \n",
            "  inflating: full_data/378.csv       \n",
            "  inflating: full_data/379.csv       \n",
            "  inflating: full_data/38.csv        \n",
            "  inflating: full_data/380.csv       \n",
            "  inflating: full_data/381.csv       \n",
            "  inflating: full_data/382.csv       \n",
            "  inflating: full_data/383.csv       \n",
            "  inflating: full_data/384.csv       \n",
            "  inflating: full_data/385.csv       \n",
            "  inflating: full_data/386.csv       \n",
            "  inflating: full_data/387.csv       \n",
            "  inflating: full_data/388.csv       \n",
            "  inflating: full_data/389.csv       \n",
            "  inflating: full_data/39.csv        \n",
            "  inflating: full_data/390.csv       \n",
            "  inflating: full_data/391.csv       \n",
            "  inflating: full_data/392.csv       \n",
            "  inflating: full_data/393.csv       \n",
            "  inflating: full_data/394.csv       \n",
            "  inflating: full_data/395.csv       \n",
            "  inflating: full_data/396.csv       \n",
            "  inflating: full_data/397.csv       \n",
            "  inflating: full_data/398.csv       \n",
            "  inflating: full_data/399.csv       \n",
            "  inflating: full_data/4.csv         \n",
            "  inflating: full_data/40.csv        \n",
            "  inflating: full_data/400.csv       \n",
            "  inflating: full_data/401.csv       \n",
            "  inflating: full_data/402.csv       \n",
            "  inflating: full_data/403.csv       \n",
            "  inflating: full_data/404.csv       \n",
            "  inflating: full_data/405.csv       \n",
            "  inflating: full_data/406.csv       \n",
            "  inflating: full_data/407.csv       \n",
            "  inflating: full_data/408.csv       \n",
            "  inflating: full_data/409.csv       \n",
            "  inflating: full_data/41.csv        \n",
            "  inflating: full_data/410.csv       \n",
            "  inflating: full_data/411.csv       \n",
            "  inflating: full_data/412.csv       \n",
            "  inflating: full_data/413.csv       \n",
            "  inflating: full_data/414.csv       \n",
            "  inflating: full_data/415.csv       \n",
            "  inflating: full_data/416.csv       \n",
            "  inflating: full_data/417.csv       \n",
            "  inflating: full_data/418.csv       \n",
            "  inflating: full_data/419.csv       \n",
            "  inflating: full_data/42.csv        \n",
            "  inflating: full_data/420.csv       \n",
            "  inflating: full_data/421.csv       \n",
            "  inflating: full_data/422.csv       \n",
            "  inflating: full_data/423.csv       \n",
            "  inflating: full_data/424.csv       \n",
            "  inflating: full_data/425.csv       \n",
            "  inflating: full_data/426.csv       \n",
            "  inflating: full_data/427.csv       \n",
            "  inflating: full_data/428.csv       \n",
            "  inflating: full_data/429.csv       \n",
            "  inflating: full_data/43.csv        \n",
            "  inflating: full_data/430.csv       \n",
            "  inflating: full_data/431.csv       \n",
            "  inflating: full_data/432.csv       \n",
            "  inflating: full_data/433.csv       \n",
            "  inflating: full_data/434.csv       \n",
            "  inflating: full_data/435.csv       \n",
            "  inflating: full_data/436.csv       \n",
            "  inflating: full_data/437.csv       \n",
            "  inflating: full_data/438.csv       \n",
            "  inflating: full_data/439.csv       \n",
            "  inflating: full_data/44.csv        \n",
            "  inflating: full_data/440.csv       \n",
            "  inflating: full_data/441.csv       \n",
            "  inflating: full_data/442.csv       \n",
            "  inflating: full_data/443.csv       \n",
            "  inflating: full_data/444.csv       \n",
            "  inflating: full_data/445.csv       \n",
            "  inflating: full_data/446.csv       \n",
            "  inflating: full_data/447.csv       \n",
            "  inflating: full_data/448.csv       \n",
            "  inflating: full_data/449.csv       \n",
            "  inflating: full_data/45.csv        \n",
            "  inflating: full_data/450.csv       \n",
            "  inflating: full_data/451.csv       \n",
            "  inflating: full_data/452.csv       \n",
            "  inflating: full_data/453.csv       \n",
            "  inflating: full_data/454.csv       \n",
            "  inflating: full_data/455.csv       \n",
            "  inflating: full_data/456.csv       \n",
            "  inflating: full_data/457.csv       \n",
            "  inflating: full_data/458.csv       \n",
            "  inflating: full_data/459.csv       \n",
            "  inflating: full_data/46.csv        \n",
            "  inflating: full_data/460.csv       \n",
            "  inflating: full_data/461.csv       \n",
            "  inflating: full_data/462.csv       \n",
            "  inflating: full_data/463.csv       \n",
            "  inflating: full_data/464.csv       \n",
            "  inflating: full_data/465.csv       \n",
            "  inflating: full_data/466.csv       \n",
            "  inflating: full_data/467.csv       \n",
            "  inflating: full_data/468.csv       \n",
            "  inflating: full_data/469.csv       \n",
            "  inflating: full_data/47.csv        \n",
            "  inflating: full_data/470.csv       \n",
            "  inflating: full_data/471.csv       \n",
            "  inflating: full_data/472.csv       \n",
            "  inflating: full_data/473.csv       \n",
            "  inflating: full_data/474.csv       \n",
            "  inflating: full_data/475.csv       \n",
            "  inflating: full_data/476.csv       \n",
            "  inflating: full_data/477.csv       \n",
            "  inflating: full_data/478.csv       \n",
            "  inflating: full_data/479.csv       \n",
            "  inflating: full_data/48.csv        \n",
            "  inflating: full_data/480.csv       \n",
            "  inflating: full_data/481.csv       \n",
            "  inflating: full_data/482.csv       \n",
            "  inflating: full_data/483.csv       \n",
            "  inflating: full_data/484.csv       \n",
            "  inflating: full_data/485.csv       \n",
            "  inflating: full_data/486.csv       \n",
            "  inflating: full_data/487.csv       \n",
            "  inflating: full_data/488.csv       \n",
            "  inflating: full_data/489.csv       \n",
            "  inflating: full_data/49.csv        \n",
            "  inflating: full_data/490.csv       \n",
            "  inflating: full_data/491.csv       \n",
            "  inflating: full_data/492.csv       \n",
            "  inflating: full_data/493.csv       \n",
            "  inflating: full_data/494.csv       \n",
            "  inflating: full_data/495.csv       \n",
            "  inflating: full_data/496.csv       \n",
            "  inflating: full_data/497.csv       \n",
            "  inflating: full_data/498.csv       \n",
            "  inflating: full_data/499.csv       \n",
            "  inflating: full_data/5.csv         \n",
            "  inflating: full_data/50.csv        \n",
            "  inflating: full_data/500.csv       \n",
            "  inflating: full_data/501.csv       \n",
            "  inflating: full_data/502.csv       \n",
            "  inflating: full_data/503.csv       \n",
            "  inflating: full_data/504.csv       \n",
            "  inflating: full_data/505.csv       \n",
            "  inflating: full_data/506.csv       \n",
            "  inflating: full_data/507.csv       \n",
            "  inflating: full_data/508.csv       \n",
            "  inflating: full_data/509.csv       \n",
            "  inflating: full_data/51.csv        \n",
            "  inflating: full_data/510.csv       \n",
            "  inflating: full_data/511.csv       \n",
            "  inflating: full_data/512.csv       \n",
            "  inflating: full_data/513.csv       \n",
            "  inflating: full_data/514.csv       \n",
            "  inflating: full_data/515.csv       \n",
            "  inflating: full_data/516.csv       \n",
            "  inflating: full_data/517.csv       \n",
            "  inflating: full_data/518.csv       \n",
            "  inflating: full_data/519.csv       \n",
            "  inflating: full_data/52.csv        \n",
            "  inflating: full_data/520.csv       \n",
            "  inflating: full_data/521.csv       \n",
            "  inflating: full_data/522.csv       \n",
            "  inflating: full_data/523.csv       \n",
            "  inflating: full_data/524.csv       \n",
            "  inflating: full_data/525.csv       \n",
            "  inflating: full_data/526.csv       \n",
            "  inflating: full_data/527.csv       \n",
            "  inflating: full_data/528.csv       \n",
            "  inflating: full_data/529.csv       \n",
            "  inflating: full_data/53.csv        \n",
            "  inflating: full_data/530.csv       \n",
            "  inflating: full_data/531.csv       \n",
            "  inflating: full_data/532.csv       \n",
            "  inflating: full_data/533.csv       \n",
            "  inflating: full_data/534.csv       \n",
            "  inflating: full_data/535.csv       \n",
            "  inflating: full_data/536.csv       \n",
            "  inflating: full_data/537.csv       \n",
            "  inflating: full_data/538.csv       \n",
            "  inflating: full_data/539.csv       \n",
            "  inflating: full_data/54.csv        \n",
            "  inflating: full_data/540.csv       \n",
            "  inflating: full_data/541.csv       \n",
            "  inflating: full_data/542.csv       \n",
            "  inflating: full_data/543.csv       \n",
            "  inflating: full_data/544.csv       \n",
            "  inflating: full_data/545.csv       \n",
            "  inflating: full_data/546.csv       \n",
            "  inflating: full_data/547.csv       \n",
            "  inflating: full_data/548.csv       \n",
            "  inflating: full_data/549.csv       \n",
            "  inflating: full_data/55.csv        \n",
            "  inflating: full_data/550.csv       \n",
            "  inflating: full_data/551.csv       \n",
            "  inflating: full_data/552.csv       \n",
            "  inflating: full_data/553.csv       \n",
            "  inflating: full_data/554.csv       \n",
            "  inflating: full_data/555.csv       \n",
            "  inflating: full_data/556.csv       \n",
            "  inflating: full_data/557.csv       \n",
            "  inflating: full_data/558.csv       \n",
            "  inflating: full_data/559.csv       \n",
            "  inflating: full_data/56.csv        \n",
            "  inflating: full_data/560.csv       \n",
            "  inflating: full_data/561.csv       \n",
            "  inflating: full_data/562.csv       \n",
            "  inflating: full_data/563.csv       \n",
            "  inflating: full_data/564.csv       \n",
            "  inflating: full_data/565.csv       \n",
            "  inflating: full_data/566.csv       \n",
            "  inflating: full_data/567.csv       \n",
            "  inflating: full_data/568.csv       \n",
            "  inflating: full_data/569.csv       \n",
            "  inflating: full_data/57.csv        \n",
            "  inflating: full_data/570.csv       \n",
            "  inflating: full_data/571.csv       \n",
            "  inflating: full_data/572.csv       \n",
            "  inflating: full_data/573.csv       \n",
            "  inflating: full_data/574.csv       \n",
            "  inflating: full_data/575.csv       \n",
            "  inflating: full_data/576.csv       \n",
            "  inflating: full_data/577.csv       \n",
            "  inflating: full_data/578.csv       \n",
            "  inflating: full_data/579.csv       \n",
            "  inflating: full_data/58.csv        \n",
            "  inflating: full_data/580.csv       \n",
            "  inflating: full_data/581.csv       \n",
            "  inflating: full_data/582.csv       \n",
            "  inflating: full_data/583.csv       \n",
            "  inflating: full_data/584.csv       \n",
            "  inflating: full_data/585.csv       \n",
            "  inflating: full_data/586.csv       \n",
            "  inflating: full_data/587.csv       \n",
            "  inflating: full_data/588.csv       \n",
            "  inflating: full_data/589.csv       \n",
            "  inflating: full_data/59.csv        \n",
            "  inflating: full_data/590.csv       \n",
            "  inflating: full_data/591.csv       \n",
            "  inflating: full_data/592.csv       \n",
            "  inflating: full_data/593.csv       \n",
            "  inflating: full_data/594.csv       \n",
            "  inflating: full_data/595.csv       \n",
            "  inflating: full_data/596.csv       \n",
            "  inflating: full_data/597.csv       \n",
            "  inflating: full_data/598.csv       \n",
            "  inflating: full_data/599.csv       \n",
            "  inflating: full_data/6.csv         \n",
            "  inflating: full_data/60.csv        \n",
            "  inflating: full_data/600.csv       \n",
            "  inflating: full_data/601.csv       \n",
            "  inflating: full_data/602.csv       \n",
            "  inflating: full_data/603.csv       \n",
            "  inflating: full_data/604.csv       \n",
            "  inflating: full_data/605.csv       \n",
            "  inflating: full_data/606.csv       \n",
            "  inflating: full_data/607.csv       \n",
            "  inflating: full_data/608.csv       \n",
            "  inflating: full_data/609.csv       \n",
            "  inflating: full_data/61.csv        \n",
            "  inflating: full_data/610.csv       \n",
            "  inflating: full_data/611.csv       \n",
            "  inflating: full_data/612.csv       \n",
            "  inflating: full_data/613.csv       \n",
            "  inflating: full_data/614.csv       \n",
            "  inflating: full_data/615.csv       \n",
            "  inflating: full_data/616.csv       \n",
            "  inflating: full_data/617.csv       \n",
            "  inflating: full_data/618.csv       \n",
            "  inflating: full_data/619.csv       \n",
            "  inflating: full_data/62.csv        \n",
            "  inflating: full_data/620.csv       \n",
            "  inflating: full_data/621.csv       \n",
            "  inflating: full_data/622.csv       \n",
            "  inflating: full_data/623.csv       \n",
            "  inflating: full_data/624.csv       \n",
            "  inflating: full_data/625.csv       \n",
            "  inflating: full_data/626.csv       \n",
            "  inflating: full_data/627.csv       \n",
            "  inflating: full_data/628.csv       \n",
            "  inflating: full_data/629.csv       \n",
            "  inflating: full_data/63.csv        \n",
            "  inflating: full_data/630.csv       \n",
            "  inflating: full_data/631.csv       \n",
            "  inflating: full_data/632.csv       \n",
            "  inflating: full_data/633.csv       \n",
            "  inflating: full_data/634.csv       \n",
            "  inflating: full_data/635.csv       \n",
            "  inflating: full_data/636.csv       \n",
            "  inflating: full_data/637.csv       \n",
            "  inflating: full_data/638.csv       \n",
            "  inflating: full_data/639.csv       \n",
            "  inflating: full_data/64.csv        \n",
            "  inflating: full_data/640.csv       \n",
            "  inflating: full_data/641.csv       \n",
            "  inflating: full_data/642.csv       \n",
            "  inflating: full_data/643.csv       \n",
            "  inflating: full_data/644.csv       \n",
            "  inflating: full_data/645.csv       \n",
            "  inflating: full_data/646.csv       \n",
            "  inflating: full_data/647.csv       \n",
            "  inflating: full_data/648.csv       \n",
            "  inflating: full_data/649.csv       \n",
            "  inflating: full_data/65.csv        \n",
            "  inflating: full_data/650.csv       \n",
            "  inflating: full_data/651.csv       \n",
            "  inflating: full_data/652.csv       \n",
            "  inflating: full_data/653.csv       \n",
            "  inflating: full_data/654.csv       \n",
            "  inflating: full_data/655.csv       \n",
            "  inflating: full_data/656.csv       \n",
            "  inflating: full_data/657.csv       \n",
            "  inflating: full_data/658.csv       \n",
            "  inflating: full_data/659.csv       \n",
            "  inflating: full_data/66.csv        \n",
            "  inflating: full_data/660.csv       \n",
            "  inflating: full_data/661.csv       \n",
            "  inflating: full_data/662.csv       \n",
            "  inflating: full_data/663.csv       \n",
            "  inflating: full_data/664.csv       \n",
            "  inflating: full_data/665.csv       \n",
            "  inflating: full_data/666.csv       \n",
            "  inflating: full_data/667.csv       \n",
            "  inflating: full_data/668.csv       \n",
            "  inflating: full_data/669.csv       \n",
            "  inflating: full_data/67.csv        \n",
            "  inflating: full_data/670.csv       \n",
            "  inflating: full_data/671.csv       \n",
            "  inflating: full_data/672.csv       \n",
            "  inflating: full_data/673.csv       \n",
            "  inflating: full_data/674.csv       \n",
            "  inflating: full_data/675.csv       \n",
            "  inflating: full_data/676.csv       \n",
            "  inflating: full_data/677.csv       \n",
            "  inflating: full_data/678.csv       \n",
            "  inflating: full_data/679.csv       \n",
            "  inflating: full_data/68.csv        \n",
            "  inflating: full_data/680.csv       \n",
            "  inflating: full_data/681.csv       \n",
            "  inflating: full_data/682.csv       \n",
            "  inflating: full_data/683.csv       \n",
            "  inflating: full_data/684.csv       \n",
            "  inflating: full_data/685.csv       \n",
            "  inflating: full_data/686.csv       \n",
            "  inflating: full_data/687.csv       \n",
            "  inflating: full_data/688.csv       \n",
            "  inflating: full_data/689.csv       \n",
            "  inflating: full_data/69.csv        \n",
            "  inflating: full_data/690.csv       \n",
            "  inflating: full_data/691.csv       \n",
            "  inflating: full_data/692.csv       \n",
            "  inflating: full_data/693.csv       \n",
            "  inflating: full_data/694.csv       \n",
            "  inflating: full_data/695.csv       \n",
            "  inflating: full_data/696.csv       \n",
            "  inflating: full_data/697.csv       \n",
            "  inflating: full_data/698.csv       \n",
            "  inflating: full_data/699.csv       \n",
            "  inflating: full_data/7.csv         \n",
            "  inflating: full_data/70.csv        \n",
            "  inflating: full_data/700.csv       \n",
            "  inflating: full_data/701.csv       \n",
            "  inflating: full_data/702.csv       \n",
            "  inflating: full_data/703.csv       \n",
            "  inflating: full_data/704.csv       \n",
            "  inflating: full_data/705.csv       \n",
            "  inflating: full_data/706.csv       \n",
            "  inflating: full_data/707.csv       \n",
            "  inflating: full_data/708.csv       \n",
            "  inflating: full_data/709.csv       \n",
            "  inflating: full_data/71.csv        \n",
            "  inflating: full_data/710.csv       \n",
            "  inflating: full_data/711.csv       \n",
            "  inflating: full_data/712.csv       \n",
            "  inflating: full_data/713.csv       \n",
            "  inflating: full_data/714.csv       \n",
            "  inflating: full_data/715.csv       \n",
            "  inflating: full_data/716.csv       \n",
            "  inflating: full_data/717.csv       \n",
            "  inflating: full_data/718.csv       \n",
            "  inflating: full_data/719.csv       \n",
            "  inflating: full_data/72.csv        \n",
            "  inflating: full_data/720.csv       \n",
            "  inflating: full_data/721.csv       \n",
            "  inflating: full_data/722.csv       \n",
            "  inflating: full_data/723.csv       \n",
            "  inflating: full_data/724.csv       \n",
            "  inflating: full_data/725.csv       \n",
            "  inflating: full_data/726.csv       \n",
            "  inflating: full_data/727.csv       \n",
            "  inflating: full_data/728.csv       \n",
            "  inflating: full_data/729.csv       \n",
            "  inflating: full_data/73.csv        \n",
            "  inflating: full_data/730.csv       \n",
            "  inflating: full_data/731.csv       \n",
            "  inflating: full_data/732.csv       \n",
            "  inflating: full_data/733.csv       \n",
            "  inflating: full_data/734.csv       \n",
            "  inflating: full_data/735.csv       \n",
            "  inflating: full_data/736.csv       \n",
            "  inflating: full_data/737.csv       \n",
            "  inflating: full_data/738.csv       \n",
            "  inflating: full_data/739.csv       \n",
            "  inflating: full_data/74.csv        \n",
            "  inflating: full_data/740.csv       \n",
            "  inflating: full_data/741.csv       \n",
            "  inflating: full_data/742.csv       \n",
            "  inflating: full_data/743.csv       \n",
            "  inflating: full_data/744.csv       \n",
            "  inflating: full_data/745.csv       \n",
            "  inflating: full_data/746.csv       \n",
            "  inflating: full_data/747.csv       \n",
            "  inflating: full_data/748.csv       \n",
            "  inflating: full_data/749.csv       \n",
            "  inflating: full_data/75.csv        \n",
            "  inflating: full_data/750.csv       \n",
            "  inflating: full_data/751.csv       \n",
            "  inflating: full_data/752.csv       \n",
            "  inflating: full_data/753.csv       \n",
            "  inflating: full_data/754.csv       \n",
            "  inflating: full_data/755.csv       \n",
            "  inflating: full_data/756.csv       \n",
            "  inflating: full_data/757.csv       \n",
            "  inflating: full_data/758.csv       \n",
            "  inflating: full_data/759.csv       \n",
            "  inflating: full_data/76.csv        \n",
            "  inflating: full_data/760.csv       \n",
            "  inflating: full_data/761.csv       \n",
            "  inflating: full_data/762.csv       \n",
            "  inflating: full_data/763.csv       \n",
            "  inflating: full_data/764.csv       \n",
            "  inflating: full_data/765.csv       \n",
            "  inflating: full_data/766.csv       \n",
            "  inflating: full_data/767.csv       \n",
            "  inflating: full_data/768.csv       \n",
            "  inflating: full_data/769.csv       \n",
            "  inflating: full_data/77.csv        \n",
            "  inflating: full_data/770.csv       \n",
            "  inflating: full_data/771.csv       \n",
            "  inflating: full_data/772.csv       \n",
            "  inflating: full_data/773.csv       \n",
            "  inflating: full_data/774.csv       \n",
            "  inflating: full_data/775.csv       \n",
            "  inflating: full_data/776.csv       \n",
            "  inflating: full_data/777.csv       \n",
            "  inflating: full_data/778.csv       \n",
            "  inflating: full_data/779.csv       \n",
            "  inflating: full_data/78.csv        \n",
            "  inflating: full_data/780.csv       \n",
            "  inflating: full_data/781.csv       \n",
            "  inflating: full_data/782.csv       \n",
            "  inflating: full_data/783.csv       \n",
            "  inflating: full_data/784.csv       \n",
            "  inflating: full_data/785.csv       \n",
            "  inflating: full_data/786.csv       \n",
            "  inflating: full_data/787.csv       \n",
            "  inflating: full_data/788.csv       \n",
            "  inflating: full_data/789.csv       \n",
            "  inflating: full_data/79.csv        \n",
            "  inflating: full_data/790.csv       \n",
            "  inflating: full_data/791.csv       \n",
            "  inflating: full_data/792.csv       \n",
            "  inflating: full_data/793.csv       \n",
            "  inflating: full_data/794.csv       \n",
            "  inflating: full_data/795.csv       \n",
            "  inflating: full_data/796.csv       \n",
            "  inflating: full_data/797.csv       \n",
            "  inflating: full_data/798.csv       \n",
            "  inflating: full_data/799.csv       \n",
            "  inflating: full_data/8.csv         \n",
            "  inflating: full_data/80.csv        \n",
            "  inflating: full_data/800.csv       \n",
            "  inflating: full_data/801.csv       \n",
            "  inflating: full_data/802.csv       \n",
            "  inflating: full_data/803.csv       \n",
            "  inflating: full_data/804.csv       \n",
            "  inflating: full_data/805.csv       \n",
            "  inflating: full_data/806.csv       \n",
            "  inflating: full_data/807.csv       \n",
            "  inflating: full_data/808.csv       \n",
            "  inflating: full_data/809.csv       \n",
            "  inflating: full_data/81.csv        \n",
            "  inflating: full_data/810.csv       \n",
            "  inflating: full_data/811.csv       \n",
            "  inflating: full_data/812.csv       \n",
            "  inflating: full_data/813.csv       \n",
            "  inflating: full_data/814.csv       \n",
            "  inflating: full_data/815.csv       \n",
            "  inflating: full_data/816.csv       \n",
            "  inflating: full_data/817.csv       \n",
            "  inflating: full_data/818.csv       \n",
            "  inflating: full_data/819.csv       \n",
            "  inflating: full_data/82.csv        \n",
            "  inflating: full_data/820.csv       \n",
            "  inflating: full_data/821.csv       \n",
            "  inflating: full_data/822.csv       \n",
            "  inflating: full_data/823.csv       \n",
            "  inflating: full_data/824.csv       \n",
            "  inflating: full_data/825.csv       \n",
            "  inflating: full_data/826.csv       \n",
            "  inflating: full_data/827.csv       \n",
            "  inflating: full_data/828.csv       \n",
            "  inflating: full_data/829.csv       \n",
            "  inflating: full_data/83.csv        \n",
            "  inflating: full_data/830.csv       \n",
            "  inflating: full_data/831.csv       \n",
            "  inflating: full_data/832.csv       \n",
            "  inflating: full_data/833.csv       \n",
            "  inflating: full_data/834.csv       \n",
            "  inflating: full_data/835.csv       \n",
            "  inflating: full_data/836.csv       \n",
            "  inflating: full_data/837.csv       \n",
            "  inflating: full_data/838.csv       \n",
            "  inflating: full_data/839.csv       \n",
            "  inflating: full_data/84.csv        \n",
            "  inflating: full_data/840.csv       \n",
            "  inflating: full_data/841.csv       \n",
            "  inflating: full_data/842.csv       \n",
            "  inflating: full_data/843.csv       \n",
            "  inflating: full_data/844.csv       \n",
            "  inflating: full_data/845.csv       \n",
            "  inflating: full_data/846.csv       \n",
            "  inflating: full_data/847.csv       \n",
            "  inflating: full_data/848.csv       \n",
            "  inflating: full_data/849.csv       \n",
            "  inflating: full_data/85.csv        \n",
            "  inflating: full_data/850.csv       \n",
            "  inflating: full_data/851.csv       \n",
            "  inflating: full_data/852.csv       \n",
            "  inflating: full_data/853.csv       \n",
            "  inflating: full_data/854.csv       \n",
            "  inflating: full_data/855.csv       \n",
            "  inflating: full_data/856.csv       \n",
            "  inflating: full_data/857.csv       \n",
            "  inflating: full_data/858.csv       \n",
            "  inflating: full_data/859.csv       \n",
            "  inflating: full_data/86.csv        \n",
            "  inflating: full_data/860.csv       \n",
            "  inflating: full_data/861.csv       \n",
            "  inflating: full_data/862.csv       \n",
            "  inflating: full_data/863.csv       \n",
            "  inflating: full_data/864.csv       \n",
            "  inflating: full_data/865.csv       \n",
            "  inflating: full_data/866.csv       \n",
            "  inflating: full_data/867.csv       \n",
            "  inflating: full_data/868.csv       \n",
            "  inflating: full_data/869.csv       \n",
            "  inflating: full_data/87.csv        \n",
            "  inflating: full_data/870.csv       \n",
            "  inflating: full_data/871.csv       \n",
            "  inflating: full_data/872.csv       \n",
            "  inflating: full_data/873.csv       \n",
            "  inflating: full_data/874.csv       \n",
            "  inflating: full_data/875.csv       \n",
            "  inflating: full_data/876.csv       \n",
            "  inflating: full_data/877.csv       \n",
            "  inflating: full_data/878.csv       \n",
            "  inflating: full_data/879.csv       \n",
            "  inflating: full_data/88.csv        \n",
            "  inflating: full_data/880.csv       \n",
            "  inflating: full_data/881.csv       \n",
            "  inflating: full_data/882.csv       \n",
            "  inflating: full_data/883.csv       \n",
            "  inflating: full_data/884.csv       \n",
            "  inflating: full_data/885.csv       \n",
            "  inflating: full_data/886.csv       \n",
            "  inflating: full_data/887.csv       \n",
            "  inflating: full_data/888.csv       \n",
            "  inflating: full_data/889.csv       \n",
            "  inflating: full_data/89.csv        \n",
            "  inflating: full_data/890.csv       \n",
            "  inflating: full_data/891.csv       \n",
            "  inflating: full_data/892.csv       \n",
            "  inflating: full_data/893.csv       \n",
            "  inflating: full_data/894.csv       \n",
            "  inflating: full_data/895.csv       \n",
            "  inflating: full_data/896.csv       \n",
            "  inflating: full_data/897.csv       \n",
            "  inflating: full_data/898.csv       \n",
            "  inflating: full_data/899.csv       \n",
            "  inflating: full_data/9.csv         \n",
            "  inflating: full_data/90.csv        \n",
            "  inflating: full_data/900.csv       \n",
            "  inflating: full_data/901.csv       \n",
            "  inflating: full_data/902.csv       \n",
            "  inflating: full_data/903.csv       \n",
            "  inflating: full_data/904.csv       \n",
            "  inflating: full_data/905.csv       \n",
            "  inflating: full_data/906.csv       \n",
            "  inflating: full_data/907.csv       \n",
            "  inflating: full_data/908.csv       \n",
            "  inflating: full_data/909.csv       \n",
            "  inflating: full_data/91.csv        \n",
            "  inflating: full_data/910.csv       \n",
            "  inflating: full_data/911.csv       \n",
            "  inflating: full_data/912.csv       \n",
            "  inflating: full_data/913.csv       \n",
            "  inflating: full_data/914.csv       \n",
            "  inflating: full_data/915.csv       \n",
            "  inflating: full_data/916.csv       \n",
            "  inflating: full_data/917.csv       \n",
            "  inflating: full_data/918.csv       \n",
            "  inflating: full_data/919.csv       \n",
            "  inflating: full_data/92.csv        \n",
            "  inflating: full_data/920.csv       \n",
            "  inflating: full_data/921.csv       \n",
            "  inflating: full_data/922.csv       \n",
            "  inflating: full_data/923.csv       \n",
            "  inflating: full_data/924.csv       \n",
            "  inflating: full_data/925.csv       \n",
            "  inflating: full_data/926.csv       \n",
            "  inflating: full_data/927.csv       \n",
            "  inflating: full_data/928.csv       \n",
            "  inflating: full_data/929.csv       \n",
            "  inflating: full_data/93.csv        \n",
            "  inflating: full_data/930.csv       \n",
            "  inflating: full_data/931.csv       \n",
            "  inflating: full_data/932.csv       \n",
            "  inflating: full_data/933.csv       \n",
            "  inflating: full_data/934.csv       \n",
            "  inflating: full_data/935.csv       \n",
            "  inflating: full_data/936.csv       \n",
            "  inflating: full_data/937.csv       \n",
            "  inflating: full_data/938.csv       \n",
            "  inflating: full_data/939.csv       \n",
            "  inflating: full_data/94.csv        \n",
            "  inflating: full_data/940.csv       \n",
            "  inflating: full_data/941.csv       \n",
            "  inflating: full_data/942.csv       \n",
            "  inflating: full_data/943.csv       \n",
            "  inflating: full_data/944.csv       \n",
            "  inflating: full_data/945.csv       \n",
            "  inflating: full_data/946.csv       \n",
            "  inflating: full_data/947.csv       \n",
            "  inflating: full_data/948.csv       \n",
            "  inflating: full_data/949.csv       \n",
            "  inflating: full_data/95.csv        \n",
            "  inflating: full_data/950.csv       \n",
            "  inflating: full_data/951.csv       \n",
            "  inflating: full_data/952.csv       \n",
            "  inflating: full_data/953.csv       \n",
            "  inflating: full_data/954.csv       \n",
            "  inflating: full_data/955.csv       \n",
            "  inflating: full_data/956.csv       \n",
            "  inflating: full_data/957.csv       \n",
            "  inflating: full_data/958.csv       \n",
            "  inflating: full_data/959.csv       \n",
            "  inflating: full_data/96.csv        \n",
            "  inflating: full_data/960.csv       \n",
            "  inflating: full_data/961.csv       \n",
            "  inflating: full_data/962.csv       \n",
            "  inflating: full_data/963.csv       \n",
            "  inflating: full_data/964.csv       \n",
            "  inflating: full_data/965.csv       \n",
            "  inflating: full_data/966.csv       \n",
            "  inflating: full_data/967.csv       \n",
            "  inflating: full_data/968.csv       \n",
            "  inflating: full_data/969.csv       \n",
            "  inflating: full_data/97.csv        \n",
            "  inflating: full_data/970.csv       \n",
            "  inflating: full_data/971.csv       \n",
            "  inflating: full_data/972.csv       \n",
            "  inflating: full_data/973.csv       \n",
            "  inflating: full_data/974.csv       \n",
            "  inflating: full_data/975.csv       \n",
            "  inflating: full_data/976.csv       \n",
            "  inflating: full_data/977.csv       \n",
            "  inflating: full_data/978.csv       \n",
            "  inflating: full_data/979.csv       \n",
            "  inflating: full_data/98.csv        \n",
            "  inflating: full_data/980.csv       \n",
            "  inflating: full_data/981.csv       \n",
            "  inflating: full_data/982.csv       \n",
            "  inflating: full_data/983.csv       \n",
            "  inflating: full_data/984.csv       \n",
            "  inflating: full_data/985.csv       \n",
            "  inflating: full_data/986.csv       \n",
            "  inflating: full_data/987.csv       \n",
            "  inflating: full_data/988.csv       \n",
            "  inflating: full_data/989.csv       \n",
            "  inflating: full_data/99.csv        \n",
            "  inflating: full_data/990.csv       \n",
            "  inflating: full_data/991.csv       \n",
            "  inflating: full_data/992.csv       \n",
            "  inflating: full_data/993.csv       \n",
            "  inflating: full_data/994.csv       \n",
            "  inflating: full_data/995.csv       \n",
            "  inflating: full_data/996.csv       \n",
            "  inflating: full_data/997.csv       \n",
            "  inflating: full_data/998.csv       \n",
            "  inflating: full_data/999.csv       \n",
            "  inflating: full_data/full_data.csv  \n",
            "  inflating: full_data/pH.xlsx       \n",
            "  inflating: full_data/spectra.xlsx  \n",
            "  inflating: full_data/Y_answers.xlsx  \n",
            "  inflating: full_data/Y_ions.csv    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xyhyk1sgbJ5f"
      },
      "source": [
        "###Customized data class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0lNtnaDyTWb"
      },
      "source": [
        "class CDS_2D_Dataset(Dataset):\n",
        "    def __init__(self, annotations_file, spec_dir, transform=None, target_transform=None):\n",
        "      '''annotations_file - the file which contains lables of the samples included in training/validation/test sets'''\n",
        "      self.spec_labels = pd.read_csv(annotations_file, sep=',').iloc[:,1:] # labels (concentrations for 4 ions) for all the samples from annotation file (Y_ions.csv)\n",
        "      self.spec_number = pd.read_csv(annotations_file, sep=',').iloc[:,0] # numbers for all the samples from annotation file (Y_ions.csv)\n",
        "      self.spec_dir = spec_dir # folder where csv files are located\n",
        "      self.transform = transform \n",
        "      self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.spec_labels)#length of the dataset\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.spec_labels.iloc[idx] # get the label of the sample via sample's index\n",
        "        sp = np.array(pd.read_csv(self.spec_dir + str(self.spec_number[idx])+'.csv').iloc[1:,1:-1], dtype='float32') # get the EEM of the sample via sample's index\n",
        "        sp[sp<0]=0 # here we zero negative values of intensities\n",
        "        spec = torch.from_numpy(sp).unsqueeze(0) # add dimension for channels of cnn\n",
        "        \n",
        "        if self.transform:\n",
        "            spec = self.transform(spec)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "            \n",
        "        return spec, torch.from_numpy(np.array(label, dtype='float32')) # return spectrum and corresponding labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSlQOSIWpv9-"
      },
      "source": [
        "#Calculate mean and std\n",
        "\n",
        "def mean_std(train_dataloader):\n",
        "    mean = 0.0\n",
        "    for specs, _ in train_dataloader:\n",
        "        batch_samples = specs.size(0) \n",
        "        specs = specs.view(batch_samples, specs.size(1), -1)\n",
        "        mean += specs.mean(2).sum(0)\n",
        "    mean = mean / len(train_dataloader.dataset)\n",
        "\n",
        "    var = 0.0\n",
        "    for specs, _ in train_dataloader:\n",
        "        batch_samples = specs.size(0)\n",
        "        specs = specs.view(batch_samples, specs.size(1), -1)\n",
        "        var += ((specs - mean.unsqueeze(1))**2).sum([0,2])\n",
        "    std = torch.sqrt(var / (len(train_dataloader.dataset)*500*41))\n",
        "\n",
        "    return mean, std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-8CEMbweP12"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwa9YmeFeMcB"
      },
      "source": [
        "#2D CNN class (basic)\n",
        "class TwoDCNN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "      \n",
        "        super().__init__() # since Python 3.0\n",
        "        \n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "\n",
        "        self.fc1 = nn.Linear(16 * 244 * 14, 160)\n",
        "        self.fc2 = nn.Linear(160, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSHg2zXUecYg"
      },
      "source": [
        "def reset_weights(m):\n",
        "    '''\n",
        "    Try resetting model weights to avoid weight leakage.\n",
        "    '''\n",
        "    for layer in m.children():\n",
        "        if hasattr(layer, 'reset_parameters'):\n",
        "            print(f'Reset trainable parameters of layer = {layer}')\n",
        "            layer.reset_parameters()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjfBc9ZwPpMU"
      },
      "source": [
        "#Write the outputs of the network\n",
        "def write_predictions(N, model_name, split_path,dataloader,dset):\n",
        "    \n",
        "    #load the model\n",
        "    checkpoint = torch.load(split_path + 'model'+model_name+'.pth')\n",
        "    N.load_state_dict(checkpoint['model_state_dict'])\n",
        "    \n",
        "    #load optimizer\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    \n",
        "    last_best_epoch = checkpoint['epoch'] #the epoch with minimum loss function that occured during training\n",
        "    loss = checkpoint['loss']\n",
        "    N.eval()\n",
        "\n",
        "    y_ae = np.zeros((1,4))\n",
        "    y_ae_true = np.zeros((1,4))\n",
        "    \n",
        "    #write the outputs of the model\n",
        "    for specs, labels in dataloader:\n",
        "        outputs = N(specs) # get the outputs from the network\n",
        "        outputs[outputs<0]=0 #we zero negative outputs as they are impossible for concentration values\n",
        "        ae = outputs.detach().numpy()\n",
        "        ae_true = labels.detach().numpy()\n",
        "        #np.concatenate((y_ae, ae), axis=0)\n",
        "        y_ae = np.concatenate((y_ae, ae), axis=0) # columns with networks's output for the dataloader\n",
        "        y_ae_true = np.concatenate((y_ae_true, ae_true), axis=0) # columns with true output for the dataloader\n",
        "\n",
        "    a = ['Cu','Ni','Cr','NO3']\n",
        "    pd.DataFrame(y_ae).to_csv(split_path + 'Y_out_'+dset+'.csv',sep=',', header = a)\n",
        "    pd.DataFrame(y_ae_true).to_csv(split_path + 'Y_true_'+dset+'.csv',sep=',', header = a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42vboWz6PuUn"
      },
      "source": [
        "# calculate mae, rmse, r2 for dataloader\n",
        "import math\n",
        "\n",
        "def calculate_metrics(model, loader):\n",
        "    running_mae = torch.zeros(1,4)\n",
        "    running_mse = torch.zeros(1,4)\n",
        "    y_sum = torch.zeros(1,4)\n",
        "    num_examples = 0\n",
        "    total_sum_squares = torch.zeros(1,4)\n",
        "    target_mean = torch.zeros(1,4)\n",
        "\n",
        "    for specs, targets in loader:\n",
        "        y_sum += targets.sum(dim=0)\n",
        "        num_examples += specs.shape[0]\n",
        "\n",
        "    num_examples = 0\n",
        "    for specs, targets in loader:\n",
        "        preds = model(specs)\n",
        "        preds[preds<0]=0\n",
        "\n",
        "        num_examples += specs.shape[0] # batch size\n",
        "        total_sum_squares += (torch.pow(preds - y_sum, 2)).sum(dim=0)\n",
        "\n",
        "        error = torch.abs(preds - targets).sum(dim=0)\n",
        "        squared_error = ((preds - targets)*(preds - targets)).sum(dim=0)\n",
        "        running_mae += error\n",
        "        running_mse += squared_error\n",
        "  \n",
        "  \n",
        "    mae = (running_mae/num_examples).detach().numpy()\n",
        "    rmse = (torch.sqrt(running_mse/num_examples)).detach().numpy()\n",
        "    r2 = (1 - squared_error / total_sum_squares).detach().numpy()\n",
        "\n",
        "    return mae, rmse, r2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZ-VO85-AOjo"
      },
      "source": [
        "#Augmetation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCX_KTFnAODl"
      },
      "source": [
        "# Wavelength drifting modelling\n",
        "\n",
        "class Shift_by_px(object):\n",
        "    def __init__(self, pixel=1):\n",
        "        self.px = pixel\n",
        "        \n",
        "    def __call__(self, tensor):\n",
        "    \n",
        "        array = tensor.numpy()\n",
        "        new = np.zeros(array.shape)\n",
        "        dim = array.shape\n",
        "\n",
        "        for st in range(0, dim[0]):\n",
        "            for stol in range (0,dim[1]):\n",
        "                if self.px>0:\n",
        "                    if stol < self.px: new[st][stol] = array[st][0]\n",
        "                    else: new[st][stol] = array[st][stol-self.px]\n",
        "                if self.px<0:\n",
        "                    if stol >= dim[1]+self.px: new[st][stol] = array[st][dim[1]-1]\n",
        "                    else: new[st][stol] = array[st][stol-self.px]\n",
        "\n",
        "        new_tensor = torch.reshape(torch.from_numpy(new).float(), tensor.shape)\n",
        "        return new_tensor\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(pixel=)'+str(self.level)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaUbZZfMASt6"
      },
      "source": [
        "# Read shot noise and read noise modelling\n",
        "\n",
        "class Add_Uniform_Noise(object):\n",
        "    def __init__(self, level = 10):\n",
        "        self.level = level\n",
        "        \n",
        "    def __call__(self, tensor):\n",
        "        return tensor + (2*self.level*torch.rand(tensor.size())-self.level)\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(level=)'+str(self.level)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE8WJL3MAZ55"
      },
      "source": [
        "# Photon noise modelling\n",
        "class Add_Photon_Noise(object):\n",
        "    def __init__(self, level = 0.025):\n",
        "        self.level = level\n",
        "        \n",
        "    def __call__(self, tensor):\n",
        "        return tensor + self.level*torch.sqrt(torch.abs(tensor))*torch.poisson(torch.abs(tensor))\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(level=)'+str(self.level)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Z0sxg4mAjb-"
      },
      "source": [
        "# Prepare cross-validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAbPRrZHuegh"
      },
      "source": [
        "gen_path = 'full_data/'\n",
        "\n",
        "case_name = '2D_CNN_100_0_001_baseline' # the nameof the experiment\n",
        "# case_name = model_name + stopping_criterion + learning_rate + comment\n",
        "cnn_2d_path = case_name+'/'\n",
        "Y = pd.read_csv(gen_path+'Y_ions.csv', sep=';')\n",
        "\n",
        "\n",
        "k_folds = [[42,12],[612,45],[72,172],[871,48],[52,134]] #cross-validation folds\n",
        "\n",
        "'''Write files with labels for each set (training/validation/test) within cross-validation fold - annotation files for CDS_2D_Dataset'''\n",
        "\n",
        "for fold in k_folds:\n",
        "  split_path = cnn_2d_path+'split_'+ str(fold[0])+'_'+str(fold[1])+ '/'\n",
        "  os.makedirs(split_path, exist_ok=True)\n",
        "\n",
        "  Y_trn, Y_30 = train_test_split(Y, test_size=0.3, random_state=fold[0])\n",
        "  Y_vld, Y_tst = train_test_split(Y_30, test_size = 0.3333, random_state=fold[1])\n",
        "\n",
        "  a = ['sample_number','Cu','Ni','Cr','NO3']\n",
        "\n",
        "  pd.DataFrame(Y_trn).to_csv(split_path + 'Y_trn.csv',sep=',', index=False, header = a)\n",
        "  pd.DataFrame(Y_vld).to_csv(split_path + 'Y_vld.csv',sep=',', index=False, header = a)\n",
        "  pd.DataFrame(Y_tst).to_csv(split_path + 'Y_tst.csv',sep=',', index=False, header = a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-BMQTOIdp1p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "158af534-49ed-4274-8fe2-5330b9c5fdca"
      },
      "source": [
        "!pip install wandb -qqq\n",
        "import wandb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 180 kB 42.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 46.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "dmaTB_nKdrmz",
        "outputId": "d2766f46-d15f-4353-b868-7dc58e33bd5a"
      },
      "source": [
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fb04b5ab63e74d3d96e4bafd316788ca",
            "63fd438dd6414d1ca93e7a9f417332fc",
            "5da8e89b6a044f8a845737ff7b276b90",
            "ce449197d2c84a26ad6b645b0fcb02e1",
            "6f6229b3b7344ccaaf7f8ac687db67fe",
            "7b5ed3a32f624da0b54e02b273d7995f",
            "3d1ca0d8f03943599cdde92da03d1fa7",
            "6d01414d04b9479d9635c40a9f351b7c",
            "9ec7a4b3f8474edf9dc0966ab9837ff2",
            "1f575fdfe1614b3c8e5d1da28a883f42",
            "74592891670f458ba6efd1b655e2533d",
            "b7f733c3dc5b49c7aa12e3db4e43bef5",
            "aac3a618663240a2a38b01f689e0166d",
            "d47268abe5634063aeb96ec93acde2ca",
            "cbb30d3fcc234cc8b043ed12f5c5341f",
            "0f97127eff284ce89b0f0490f1ac3b09"
          ]
        },
        "id": "o3CYMoGzeBeS",
        "outputId": "963d627f-a18b-4677-dca6-d6ea18cbeb94"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "model = TwoDCNN() # define model\n",
        "\n",
        "loss_function = torch.nn.MSELoss().cuda() #define loss_function\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for fold in k_folds:\n",
        "    split_path = cnn_2d_path+'split_'+ str(fold[0])+'_'+str(fold[1])+ '/'\n",
        "    \n",
        "    training_data = CDS_2D_Dataset(split_path+'Y_trn.csv',gen_path)\n",
        "    \n",
        "    validation_data = CDS_2D_Dataset(split_path+'Y_vld.csv',gen_path)\n",
        "    test_data = CDS_2D_Dataset(split_path+'Y_tst.csv',gen_path)\n",
        "\n",
        "    train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "    mean, std = mean_std(train_dataloader)\n",
        "\n",
        "    #Data import and normalization Basic\n",
        "\n",
        "    training_data = CDS_2D_Dataset(split_path+'Y_trn.csv', gen_path, transform= transforms.Compose([transforms.Normalize(mean, std)]))\n",
        "\n",
        "    validation_data = CDS_2D_Dataset(split_path+'Y_vld.csv', gen_path, transform= transforms.Compose([transforms.Normalize(mean, std)]))\n",
        "    test_data = CDS_2D_Dataset(split_path+'Y_tst.csv', gen_path, transform= transforms.Compose([transforms.Normalize(mean, std)]))\n",
        "    \n",
        "    train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "    validation_dataloader = DataLoader(validation_data, batch_size=64, shuffle=True)\n",
        "    test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
        "\n",
        "    #Augmentation via wavlength drifting modelling\n",
        "    #For data augmentation comment 'Data import and normalization Basic' and use this block instead\n",
        "    '''\n",
        "    training_data = CDS_2D_Dataset(split_path+'Y_trn.csv', gen_path, transform= transforms.Compose([transforms.Normalize(mean,std)]))\n",
        "    training_data_shift_1 = CDS_2D_Dataset(split_path+'Y_trn.csv',gen_path, transform=transforms.Compose([Shift_by_px(1),transforms.Normalize(mean,std)]))\n",
        "    training_data_shift_2 = CDS_2D_Dataset(split_path+'Y_trn.csv',gen_path, transform=transforms.Compose([Shift_by_px(-1),transforms.Normalize(mean,std)]))\n",
        "    training_data_concatenated = torch.utils.data.ConcatDataset([training_data, training_data_shift_1, training_data_shift_2])\n",
        "\n",
        "    validation_data = CDS_2D_Dataset(split_path+'Y_vld.csv', gen_path, transform= transforms.Compose([transforms.Normalize(mean,std)]))\n",
        "    test_data = CDS_2D_Dataset(split_path+'Y_tst.csv', gen_path, transform= transforms.Compose([transforms.Normalize(mean,std)]))\n",
        "\n",
        "    train_dataloader = DataLoader(training_data_concatenated, batch_size=64, shuffle=True)\n",
        "    validation_dataloader = DataLoader(validation_data, batch_size=64, shuffle=True)\n",
        "    test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
        "    '''\n",
        "    \n",
        "    #Augmentation via uniform noise modelling\n",
        "    #For data augmentation comment 'Data import and normalization Basic' and use this block instead\n",
        "    # Noise level parameters: [2.5, 5, 10]\n",
        "    '''\n",
        "    training_data = CDS_2D_Dataset(split_path+'Y_trn.csv', gen_path, transform= transforms.Compose([transforms.Normalize(mean,std)]))\n",
        "    training_data_noise = CDS_2D_Dataset(split_path+'Y_trn.csv',gen_path, transform=transforms.Compose([Add_Uniform_Noise(2.5),transforms.Normalize(mean,std)]))\n",
        "    training_data_concatenated = torch.utils.data.ConcatDataset([training_data, training_data_noise])\n",
        "\n",
        "    validation_data = CDS_2D_Dataset(split_path+'Y_vld.csv', gen_path, transform= transforms.Compose([transforms.Normalize(mean,std)]))\n",
        "    test_data = CDS_2D_Dataset(split_path+'Y_tst.csv', gen_path, transform= transforms.Compose([transforms.Normalize(mean,std)]))\n",
        "\n",
        "    train_dataloader = DataLoader(training_data_concatenated, batch_size=64, shuffle=True)\n",
        "    validation_dataloader = DataLoader(validation_data, batch_size=64, shuffle=True)\n",
        "    test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
        "\n",
        "    '''\n",
        "    #Augmentation via photon noise modelling\n",
        "    #For data augmentation comment 'Data import and normalization Basic' and use this block instead\n",
        "    # Noise level parameters: [0.025, 0.05, 0.1]\n",
        "    '''\n",
        "    training_data = CDS_2D_Dataset(split_path+'Y_trn.csv', gen_path, transform= transforms.Compose([transforms.Normalize(mean,std)]))\n",
        "    training_data_noise = CDS_2D_Dataset(split_path+'Y_trn.csv',gen_path, transform=transforms.Compose([Add_Photon_Noise(0.025),transforms.Normalize(mean,std)]))\n",
        "    training_data_concatenated = torch.utils.data.ConcatDataset([training_data, training_data_noise])\n",
        "\n",
        "    validation_data = CDS_2D_Dataset(split_path+'Y_vld.csv', gen_path, transform= transforms.Compose([transforms.Normalize(mean,std)]))\n",
        "    test_data = CDS_2D_Dataset(split_path+'Y_tst.csv', gen_path, transform= transforms.Compose([transforms.Normalize(mean,std)]))\n",
        "\n",
        "    train_dataloader = DataLoader(training_data_concatenated, batch_size=64, shuffle=True)\n",
        "    validation_dataloader = DataLoader(validation_data, batch_size=64, shuffle=True)\n",
        "    test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
        "\n",
        "    '''\n",
        "\n",
        "    for init_number in range(0,5): #Это я делаю множественную инициализацию весов сети\n",
        "\n",
        "        init_path = split_path + str(init_number)+'/'\n",
        "        os.makedirs(init_path, exist_ok=True)\n",
        "\n",
        "        # Обучение\n",
        "        # критерием остановки является ошибка на валидационном наборе - останавливаемся,\n",
        "        #если в течение 100 эпох (test_stop) ошибка на валидационном наборе (val_loss) не падала\n",
        "\n",
        "        test_stop = 100 #stopping criterion\n",
        "        max_val_loss = 10000.0\n",
        "\n",
        "        wandb.init(project = case_name)\n",
        "\n",
        "        split_name = 'split_'+ str(fold[0])+'_'+str(fold[1])\n",
        "        init_name = '_' + str(init_number)\n",
        "        model_name = '_2D_CNN'\n",
        "        wandb.run.name = split_name + init_name + model_name\n",
        "        wandb.run.save()\n",
        "\n",
        "        for epoch_step in range(0, 1000, test_stop):\n",
        "            \n",
        "            if epoch_step!=0:\n",
        "                checkpoint = torch.load(init_path + 'model'+model_name+'.pth')\n",
        "                model.load_state_dict(checkpoint['model_state_dict'])\n",
        "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "                last_best_epoch = checkpoint['epoch']\n",
        "                loss = checkpoint['loss']\n",
        "                model.train()\n",
        "                \n",
        "                if last_best_epoch + test_stop > ep:\n",
        "                    for ep in range(epoch_step, epoch_step+test_stop):\n",
        "                        for _, data in enumerate(train_dataloader, 0): # get bacth\n",
        "                            inputs, labels = data # parse batch\n",
        "                            optimizer.zero_grad() # sets the gradients of all optimized tensors to zero.\n",
        "                            outputs = model(inputs) # get outputs\n",
        "                            loss = loss_function(outputs, labels) # calculate loss\n",
        "                            loss.backward() # calculate gradients\n",
        "                            optimizer.step() # performs a single optimization step (parameter update).\n",
        "\n",
        "                        dl = 0\n",
        "                        val_loss = 0.0\n",
        "                        for specs, labels in validation_dataloader: \n",
        "                            val_loss += loss_function(model(specs),labels)\n",
        "                            dl+=1\n",
        "                        val_loss = val_loss/dl\n",
        "                            \n",
        "                            \n",
        "                            \n",
        "                        if val_loss.item() <= max_val_loss:\n",
        "                            torch.save({'epoch': ep,\n",
        "                              'model_state_dict': model.state_dict(),\n",
        "                              'optimizer_state_dict': optimizer.state_dict(),\n",
        "                              'loss': loss}, init_path + 'model'+model_name+'.pth')\n",
        "                            max_val_loss = val_loss.item()\n",
        "                        wandb.log({\"trn_loss\": loss, \"vld_loss\": val_loss})\n",
        "                else: continue    \n",
        "      \n",
        "            if epoch_step==0:\n",
        "                model.apply(reset_weights)\n",
        "\n",
        "                for ep in range(epoch_step, test_stop):\n",
        "                    for _, data in enumerate(train_dataloader, 0): # get bacth\n",
        "                        inputs, labels = data # parse batch\n",
        "                        optimizer.zero_grad() # sets the gradients of all optimized tensors to zero.\n",
        "                        outputs = model(inputs) # get outputs\n",
        "                        loss = loss_function(outputs, labels) # calculate loss\n",
        "                        loss.backward() # calculate gradients\n",
        "                        optimizer.step() # performs a single optimization step (parameter update).\n",
        "\n",
        "                    dl = 0\n",
        "                    val_loss = 0.0\n",
        "                    for specs, labels in validation_dataloader: \n",
        "                        val_loss += loss_function(model(specs),labels)\n",
        "                        dl+=1\n",
        "                    val_loss = val_loss/dl\n",
        "\n",
        "                    if val_loss.item() <= max_val_loss:\n",
        "                        torch.save({'epoch': ep,\n",
        "                          'model_state_dict': model.state_dict(),\n",
        "                          'optimizer_state_dict': optimizer.state_dict(),\n",
        "                          'loss': loss}, init_path + 'model'+model_name+'.pth')\n",
        "                        max_val_loss = val_loss.item()\n",
        "                    wandb.log({\"trn_loss\": loss, \"vld_loss\": val_loss})\n",
        "\n",
        "        trn_metrics = calculate_metrics(model, train_dataloader)\n",
        "        vld_metrics = calculate_metrics(model, validation_dataloader)\n",
        "        tst_metrics = calculate_metrics(model, test_dataloader)\n",
        "\n",
        "        wandb.log({\"trn_mae\": trn_metrics[0].sum()/4, \"trn_rmse\": trn_metrics[1].sum()/4,\"trn_r2\": trn_metrics[2].sum()/4})\n",
        "        wandb.log({\"vld_mae\": vld_metrics[0].sum()/4, \"vld_rmse\": vld_metrics[1].sum()/4,\"vld_r2\": vld_metrics[2].sum()/4})\n",
        "        wandb.log({\"tst_mae\": tst_metrics[0].sum()/4, \"tst_rmse\": tst_metrics[1].sum()/4,\"tst_r2\": tst_metrics[2].sum()/4})\n",
        "        wandb.log({\"epoch\": ep})\n",
        "\n",
        "        wandb.finish()\n",
        "\n",
        "        write_predictions(model, model_name, init_path, train_dataloader, dset = 'trn')\n",
        "        write_predictions(model, model_name, init_path, validation_dataloader, dset ='vld')\n",
        "        write_predictions(model, model_name, init_path, test_dataloader, dset ='tst')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:2ns68uy0) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 426... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb04b5ab63e74d3d96e4bafd316788ca",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
              "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>trn_loss</td><td>▁</td></tr><tr><td>vld_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
              "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>trn_loss</td><td>14.86788</td></tr><tr><td>vld_loss</td><td>12.8185</td></tr></table>\n",
              "</div></div>\n",
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
              "<br/>Synced <strong style=\"color:#cdcd00\">restful-resonance-24</strong>: <a href=\"https://wandb.ai/oe_sarmanova/2D_CNN_100_0_001_baseline/runs/2ns68uy0\" target=\"_blank\">https://wandb.ai/oe_sarmanova/2D_CNN_100_0_001_baseline/runs/2ns68uy0</a><br/>\n",
              "Find logs at: <code>./wandb/run-20211207_084817-2ns68uy0/logs</code><br/>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Successfully finished last run (ID:2ns68uy0). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/oe_sarmanova/2D_CNN_100_0_001_baseline/runs/3miemndd\" target=\"_blank\">autumn-leaf-25</a></strong> to <a href=\"https://wandb.ai/oe_sarmanova/2D_CNN_100_0_001_baseline\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reset trainable parameters of layer = Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "Reset trainable parameters of layer = Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "Reset trainable parameters of layer = Linear(in_features=54656, out_features=160, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=160, out_features=4, bias=True)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 474... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ec7a4b3f8474edf9dc0966ab9837ff2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
              "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>trn_loss</td><td>█▅▂▁▂▁▁▁▁▁</td></tr><tr><td>trn_mae</td><td>▁</td></tr><tr><td>trn_r2</td><td>▁</td></tr><tr><td>trn_rmse</td><td>▁</td></tr><tr><td>tst_mae</td><td>▁</td></tr><tr><td>tst_r2</td><td>▁</td></tr><tr><td>tst_rmse</td><td>▁</td></tr><tr><td>vld_loss</td><td>█▄▂▁▁▁▂▁▁▁</td></tr><tr><td>vld_mae</td><td>▁</td></tr><tr><td>vld_r2</td><td>▁</td></tr><tr><td>vld_rmse</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
              "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>trn_loss</td><td>3.18932</td></tr><tr><td>trn_mae</td><td>1.24767</td></tr><tr><td>trn_r2</td><td>1.0</td></tr><tr><td>trn_rmse</td><td>1.52851</td></tr><tr><td>tst_mae</td><td>1.43696</td></tr><tr><td>tst_r2</td><td>0.99999</td></tr><tr><td>tst_rmse</td><td>1.72371</td></tr><tr><td>vld_loss</td><td>3.00175</td></tr><tr><td>vld_mae</td><td>1.27202</td></tr><tr><td>vld_r2</td><td>1.0</td></tr><tr><td>vld_rmse</td><td>1.52688</td></tr></table>\n",
              "</div></div>\n",
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
              "<br/>Synced <strong style=\"color:#cdcd00\">autumn-leaf-25</strong>: <a href=\"https://wandb.ai/oe_sarmanova/2D_CNN_100_0_001_baseline/runs/3miemndd\" target=\"_blank\">https://wandb.ai/oe_sarmanova/2D_CNN_100_0_001_baseline/runs/3miemndd</a><br/>\n",
              "Find logs at: <code>./wandb/run-20211207_084925-3miemndd/logs</code><br/>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/oe_sarmanova/2D_CNN_100_0_001_baseline/runs/1twx6vzy\" target=\"_blank\">dandy-surf-26</a></strong> to <a href=\"https://wandb.ai/oe_sarmanova/2D_CNN_100_0_001_baseline\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reset trainable parameters of layer = Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "Reset trainable parameters of layer = Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "Reset trainable parameters of layer = Linear(in_features=54656, out_features=160, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=160, out_features=4, bias=True)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-2b7b5377b820>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_stop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# get bacth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;31m# parse batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sets the gradients of all optimized tensors to zero.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-e4607e542ec5>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# get the label of the sample via sample's index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0msp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec_number\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get the EEM of the sample via sample's index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0msp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;31m# here we zero negative values of intensities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# add dimension for channels of cnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[0mnew_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_currow\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnew_rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         ]\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_arrays\u001b[0;34m(arrays, names, axes)\u001b[0m\n\u001b[1;32m   1690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mform_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mform_blocks\u001b[0;34m(arrays, names, axes)\u001b[0m\n\u001b[1;32m   1744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m         \u001b[0mblock_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_block_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1746\u001b[0;31m         \u001b[0mitems_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblock_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m     \u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBlock\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}