{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import KFold\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random states for splits\n",
    "[[42,12],[23,5],[37,51]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_path = 'Desktop/Gala_Salts/'\n",
    "path_to_data = gen_path + 'full_data/'\n",
    "path_to_out = gen_path + 'split_2/'\n",
    "Y = np.array(pd.read_csv(path_to_data+'Y_ions.csv', sep=';'))\n",
    "\n",
    "#Form 3 data splits for cross-validation\n",
    "\n",
    "Y_trn, Y_30 = train_test_split(Y, test_size=0.3, random_state=23)\n",
    "Y_vld, Y_tst = train_test_split(Y_30, test_size = 0.3333, random_state=5)\n",
    "\n",
    "a = ['sample_number','Cu','Ni','Cr','NO3']\n",
    "pd.DataFrame(Y_trn).to_csv(path_to_out + 'Y_trn.csv',sep=',', header = a)\n",
    "pd.DataFrame(Y_vld).to_csv(path_to_out + 'Y_vld.csv',sep=',', header = a)\n",
    "pd.DataFrame(Y_tst).to_csv(path_to_out + 'Y_tst.csv',sep=',', header = a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Customized dataset class\n",
    "\n",
    "class CDS_Dataset(Dataset):\n",
    "    def __init__(self, annotations_file, spec_dir, transform=None, target_transform=None):\n",
    "        self.spec_labels = pd.read_csv(annotations_file, sep=',').iloc[:,1:]\n",
    "        self.spec_number = pd.read_csv(annotations_file, sep=',').iloc[:,0]\n",
    "        self.spec_dir = spec_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.spec_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.spec_labels.iloc[idx]\n",
    "        spec = torch.from_numpy(np.array(pd.read_csv(self.spec_dir + str(self.spec_number[idx])+'.csv').iloc[1:,1:-1], dtype='float32')).unsqueeze(0)\n",
    "        if self.transform:\n",
    "            spec = self.transform(spec)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return spec, torch.from_numpy(np.array(label, dtype='float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data to calculate mean and std\n",
    "training_data = CDS_Dataset(path_to_out+'Y_trn.csv',path_to_data)\n",
    "validation_data = CDS_Dataset(path_to_out+'Y_vld.csv',path_to_data)\n",
    "test_data = CDS_Dataset(path_to_out+'Y_tst.csv',path_to_data)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate mean and std\n",
    "mean = 0.0\n",
    "for specs, _ in train_dataloader:\n",
    "    batch_samples = specs.size(0) \n",
    "    specs = specs.view(batch_samples, specs.size(1), -1)\n",
    "    mean += specs.mean(2).sum(0)\n",
    "mean = mean / len(train_dataloader.dataset)\n",
    "\n",
    "var = 0.0\n",
    "for specs, _ in train_dataloader:\n",
    "    batch_samples = specs.size(0)\n",
    "    specs = specs.view(batch_samples, specs.size(1), -1)\n",
    "    var += ((specs - mean.unsqueeze(1))**2).sum([0,2])\n",
    "std = torch.sqrt(var / (len(train_dataloader.dataset)*500*41))\n",
    "\n",
    "print('mean:', mean, 'std:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and Normalize data\n",
    "training_data = CDS_Dataset(path_to_out+'Y_trn.csv',path_to_data, transform= transforms.Normalize((mean), (std)) )\n",
    "validation_data = CDS_Dataset(path_to_out+'Y_vld.csv',path_to_data, transform= transforms.Normalize((mean), (std)) )\n",
    "test_data = CDS_Dataset(path_to_out+'Y_tst.csv',path_to_data, transform= transforms.Normalize((mean), (std)) )\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2D CNN class\n",
    "class TwoLayerCNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "      \n",
    "        super().__init__() # since Python 3.0\n",
    "        \n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "\n",
    "        self.fc1 = nn.Linear(16 * 244 * 14, 160)\n",
    "        self.fc2 = nn.Linear(160, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TwoLayerCNN(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=54656, out_features=160, bias=True)\n",
      "  (fc2): Linear(in_features=160, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Model instance\n",
    "N = TwoLayerCNN()\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch=0 loss=16.0266\n",
      "Epoch=1 loss=7.8551\n",
      "Epoch=2 loss=3.9673\n",
      "Epoch=3 loss=3.6440\n",
      "Epoch=4 loss=4.0431\n",
      "Epoch=5 loss=2.8213\n",
      "Epoch=6 loss=3.2827\n",
      "Epoch=7 loss=2.7267\n",
      "Epoch=8 loss=3.1312\n",
      "Epoch=9 loss=3.0848\n",
      "Epoch=10 loss=2.8178\n",
      "Epoch=11 loss=2.4554\n",
      "Epoch=12 loss=2.8846\n",
      "Epoch=13 loss=2.2139\n",
      "Epoch=14 loss=3.1007\n",
      "Epoch=15 loss=3.5549\n",
      "Epoch=16 loss=2.8327\n",
      "Epoch=17 loss=2.2032\n",
      "Epoch=18 loss=2.3103\n",
      "Epoch=19 loss=2.1975\n",
      "Epoch=20 loss=2.3770\n",
      "Epoch=21 loss=2.2277\n",
      "Epoch=22 loss=2.4514\n",
      "Epoch=23 loss=2.0719\n",
      "Epoch=24 loss=2.3634\n",
      "Epoch=25 loss=2.4054\n",
      "Epoch=26 loss=2.8007\n",
      "Epoch=27 loss=2.4998\n",
      "Epoch=28 loss=2.1727\n",
      "Epoch=29 loss=2.0390\n",
      "Epoch=30 loss=2.1908\n",
      "Epoch=31 loss=2.3135\n",
      "Epoch=32 loss=1.4218\n",
      "Epoch=33 loss=1.6513\n",
      "Epoch=34 loss=2.1037\n",
      "Epoch=35 loss=1.6589\n",
      "Epoch=36 loss=1.5670\n",
      "Epoch=37 loss=2.4620\n",
      "Epoch=38 loss=1.9223\n",
      "Epoch=39 loss=2.2418\n",
      "Epoch=40 loss=2.0712\n",
      "Epoch=41 loss=1.9443\n",
      "Epoch=42 loss=1.4474\n",
      "Epoch=43 loss=1.7702\n",
      "Epoch=44 loss=1.8785\n",
      "Epoch=45 loss=1.5434\n",
      "Epoch=46 loss=1.4556\n",
      "Epoch=47 loss=2.8626\n",
      "Epoch=48 loss=1.7885\n",
      "Epoch=49 loss=1.8076\n",
      "Epoch=50 loss=1.7793\n",
      "Epoch=51 loss=2.1524\n",
      "Epoch=52 loss=1.6076\n",
      "Epoch=53 loss=1.3070\n",
      "Epoch=54 loss=1.4963\n",
      "Epoch=55 loss=1.3851\n",
      "Epoch=56 loss=1.5878\n",
      "Epoch=57 loss=1.2409\n",
      "Epoch=58 loss=1.3401\n",
      "Epoch=59 loss=1.1839\n",
      "Epoch=60 loss=1.2216\n",
      "Epoch=61 loss=1.5207\n",
      "Epoch=62 loss=1.2225\n",
      "Epoch=63 loss=1.2249\n",
      "Epoch=64 loss=1.2355\n",
      "Epoch=65 loss=1.2707\n",
      "Epoch=66 loss=0.9558\n",
      "Epoch=67 loss=1.6532\n",
      "Epoch=68 loss=2.2494\n",
      "Epoch=69 loss=1.3798\n",
      "Epoch=70 loss=1.2115\n",
      "Epoch=71 loss=1.2525\n",
      "Epoch=72 loss=0.9067\n",
      "Epoch=73 loss=1.0373\n",
      "Epoch=74 loss=1.1334\n",
      "Epoch=75 loss=1.1401\n",
      "Epoch=76 loss=1.5505\n",
      "Epoch=77 loss=0.7204\n",
      "Epoch=78 loss=0.8031\n",
      "Epoch=79 loss=0.7844\n",
      "Epoch=80 loss=1.1359\n",
      "Epoch=81 loss=0.6527\n",
      "Epoch=82 loss=0.9718\n",
      "Epoch=83 loss=0.8806\n",
      "Epoch=84 loss=0.8575\n",
      "Epoch=85 loss=0.8461\n",
      "Epoch=86 loss=0.9890\n",
      "Epoch=87 loss=0.7580\n",
      "Epoch=88 loss=0.9917\n",
      "Epoch=89 loss=0.6008\n",
      "Epoch=90 loss=0.9078\n",
      "Epoch=91 loss=0.9334\n",
      "Epoch=92 loss=0.6731\n",
      "Epoch=93 loss=0.6731\n",
      "Epoch=94 loss=0.8820\n",
      "Epoch=95 loss=0.8126\n",
      "Epoch=96 loss=0.6370\n",
      "Epoch=97 loss=1.2945\n",
      "Epoch=98 loss=0.6711\n",
      "Epoch=99 loss=0.6316\n",
      "Epoch=100 loss=0.6971 val_loss=0.5032\n",
      "Epoch=101 loss=0.8889 val_loss=0.7498\n",
      "Epoch=102 loss=0.6430 val_loss=1.6508\n",
      "Epoch=103 loss=0.5051 val_loss=1.6716\n",
      "Epoch=104 loss=0.7088 val_loss=1.4913\n",
      "Epoch=105 loss=0.7614 val_loss=1.6659\n",
      "Epoch=106 loss=0.4793 val_loss=1.7486\n",
      "Epoch=107 loss=0.9692 val_loss=0.3583\n",
      "Epoch=108 loss=0.6625 val_loss=0.5100\n",
      "Epoch=109 loss=0.5870 val_loss=0.7280\n",
      "Epoch=110 loss=0.4213 val_loss=0.5621\n",
      "Epoch=111 loss=0.6582 val_loss=1.2633\n",
      "Epoch=112 loss=0.5731 val_loss=0.3223\n",
      "Epoch=113 loss=0.9247 val_loss=2.0362\n",
      "Epoch=114 loss=1.6752 val_loss=0.3793\n",
      "Epoch=115 loss=0.6438 val_loss=1.5259\n",
      "Epoch=116 loss=0.6544 val_loss=1.8591\n",
      "Epoch=117 loss=0.8043 val_loss=0.4752\n",
      "Epoch=118 loss=0.7305 val_loss=0.7847\n",
      "Epoch=119 loss=0.6334 val_loss=0.8804\n",
      "Epoch=120 loss=0.5476 val_loss=0.3766\n",
      "Epoch=121 loss=0.4854 val_loss=0.3940\n",
      "Epoch=122 loss=0.3909 val_loss=1.0800\n",
      "Epoch=123 loss=0.4524 val_loss=1.4185\n",
      "Epoch=124 loss=0.4413 val_loss=0.8315\n",
      "Epoch=125 loss=0.6472 val_loss=0.3524\n",
      "Epoch=126 loss=0.6616 val_loss=0.6660\n",
      "Epoch=127 loss=0.4537 val_loss=0.6578\n",
      "Epoch=128 loss=0.4033 val_loss=1.4706\n",
      "Epoch=129 loss=0.4874 val_loss=0.1337\n",
      "Epoch=130 loss=0.7900 val_loss=1.2075\n",
      "Epoch=131 loss=0.4281 val_loss=0.4538\n",
      "Epoch=132 loss=0.4391 val_loss=0.8320\n",
      "Epoch=133 loss=0.5063 val_loss=0.6063\n",
      "Epoch=134 loss=0.4788 val_loss=1.0736\n",
      "Epoch=135 loss=0.5152 val_loss=1.1957\n",
      "Epoch=136 loss=0.7009 val_loss=0.6524\n",
      "Epoch=137 loss=0.6215 val_loss=1.7721\n",
      "Epoch=138 loss=0.5663 val_loss=0.5613\n",
      "Epoch=139 loss=0.5207 val_loss=1.8737\n",
      "Epoch=140 loss=0.4900 val_loss=1.1468\n",
      "Epoch=141 loss=0.5179 val_loss=1.2411\n",
      "Epoch=142 loss=0.4371 val_loss=0.6716\n",
      "Epoch=143 loss=0.6638 val_loss=0.7192\n",
      "Epoch=144 loss=0.4010 val_loss=0.8476\n",
      "Epoch=145 loss=0.5919 val_loss=0.6178\n",
      "Epoch=146 loss=0.4911 val_loss=0.3084\n",
      "Epoch=147 loss=0.3437 val_loss=1.7270\n",
      "Epoch=148 loss=0.2619 val_loss=1.6849\n",
      "Epoch=149 loss=0.4099 val_loss=1.1532\n",
      "Epoch=150 loss=0.3562 val_loss=1.1734\n",
      "Epoch=151 loss=0.3807 val_loss=0.5785\n",
      "Epoch=152 loss=0.2948 val_loss=0.7760\n",
      "Epoch=153 loss=0.3049 val_loss=1.0491\n",
      "Epoch=154 loss=0.3778 val_loss=0.1876\n",
      "Epoch=155 loss=0.4188 val_loss=0.2200\n",
      "Epoch=156 loss=0.3114 val_loss=0.2414\n",
      "Epoch=157 loss=0.3675 val_loss=0.9777\n",
      "Epoch=158 loss=0.5035 val_loss=0.7508\n",
      "Epoch=159 loss=0.5166 val_loss=0.8842\n",
      "Epoch=160 loss=0.2912 val_loss=0.4755\n",
      "Epoch=161 loss=0.5422 val_loss=1.1207\n",
      "Epoch=162 loss=0.5506 val_loss=0.9006\n",
      "Epoch=163 loss=0.3332 val_loss=0.6257\n",
      "Epoch=164 loss=0.3839 val_loss=1.1687\n",
      "Epoch=165 loss=0.2844 val_loss=0.6347\n",
      "Epoch=166 loss=0.3218 val_loss=0.4704\n",
      "Epoch=167 loss=0.3411 val_loss=0.6321\n",
      "Epoch=168 loss=0.2344 val_loss=0.4352\n",
      "Epoch=169 loss=0.7414 val_loss=1.0821\n",
      "Epoch=170 loss=0.3457 val_loss=1.1984\n",
      "Epoch=171 loss=0.3818 val_loss=0.7707\n",
      "Epoch=172 loss=0.3598 val_loss=0.3927\n",
      "Epoch=173 loss=0.3222 val_loss=0.4754\n",
      "Epoch=174 loss=0.2993 val_loss=0.1504\n",
      "Epoch=175 loss=0.2999 val_loss=0.8099\n",
      "Epoch=176 loss=0.3709 val_loss=0.4287\n",
      "Epoch=177 loss=0.3442 val_loss=0.4430\n",
      "Epoch=178 loss=0.5414 val_loss=0.5275\n",
      "Epoch=179 loss=0.3085 val_loss=1.1102\n",
      "Epoch=180 loss=0.5030 val_loss=1.3753\n",
      "Epoch=181 loss=0.3783 val_loss=0.1166\n",
      "Epoch=182 loss=0.3286 val_loss=1.1672\n",
      "Epoch=183 loss=0.5579 val_loss=0.6624\n",
      "Epoch=184 loss=0.2759 val_loss=0.8263\n",
      "Epoch=185 loss=0.2757 val_loss=1.7329\n",
      "Epoch=186 loss=0.5439 val_loss=0.6290\n",
      "Epoch=187 loss=0.3681 val_loss=0.9459\n",
      "Epoch=188 loss=0.2609 val_loss=0.3734\n",
      "Epoch=189 loss=0.2577 val_loss=0.2723\n",
      "Epoch=190 loss=0.2996 val_loss=1.5811\n",
      "Epoch=191 loss=0.3290 val_loss=1.4410\n",
      "Epoch=192 loss=0.2044 val_loss=0.9156\n",
      "Epoch=193 loss=0.3524 val_loss=0.5319\n",
      "Epoch=194 loss=0.3262 val_loss=0.3132\n",
      "Epoch=195 loss=0.4034 val_loss=1.1730\n",
      "Epoch=196 loss=0.3112 val_loss=0.6541\n",
      "Epoch=197 loss=0.2141 val_loss=0.4592\n",
      "Epoch=198 loss=0.4616 val_loss=0.5561\n",
      "Epoch=199 loss=0.6188 val_loss=0.8942\n",
      "Epoch=200 loss=0.2870 val_loss=0.7959\n",
      "Epoch=201 loss=0.2733 val_loss=0.4919\n",
      "Epoch=202 loss=0.3253 val_loss=0.7177\n",
      "Epoch=203 loss=0.3106 val_loss=0.5857\n",
      "Epoch=204 loss=0.1864 val_loss=0.5332\n",
      "Epoch=205 loss=0.3951 val_loss=1.3587\n",
      "Epoch=206 loss=0.5470 val_loss=1.5946\n",
      "Epoch=207 loss=0.3062 val_loss=1.9992\n",
      "Epoch=208 loss=0.5504 val_loss=0.4906\n",
      "Epoch=209 loss=0.3010 val_loss=1.0496\n",
      "Epoch=210 loss=0.3927 val_loss=1.8795\n",
      "Epoch=211 loss=0.2385 val_loss=0.6112\n",
      "Epoch=212 loss=0.2534 val_loss=0.7227\n",
      "Epoch=213 loss=0.2976 val_loss=1.2377\n",
      "Epoch=214 loss=0.3036 val_loss=1.2096\n",
      "Epoch=215 loss=0.4273 val_loss=1.9907\n",
      "Epoch=216 loss=0.3504 val_loss=0.8722\n",
      "Epoch=217 loss=0.2346 val_loss=0.6990\n",
      "Epoch=218 loss=0.2900 val_loss=1.0494\n",
      "Epoch=219 loss=0.1838 val_loss=0.9610\n",
      "Epoch=220 loss=0.3608 val_loss=0.6912\n",
      "Epoch=221 loss=0.2860 val_loss=1.1777\n",
      "Epoch=222 loss=0.2343 val_loss=0.4577\n",
      "Epoch=223 loss=0.3565 val_loss=1.8643\n",
      "Epoch=224 loss=0.2803 val_loss=0.9985\n",
      "Epoch=225 loss=0.3087 val_loss=0.7010\n",
      "Epoch=226 loss=0.3235 val_loss=1.3828\n",
      "Epoch=227 loss=0.2454 val_loss=0.1050\n",
      "Epoch=228 loss=0.2302 val_loss=0.4771\n",
      "Epoch=229 loss=0.2425 val_loss=0.5163\n",
      "Epoch=230 loss=0.1998 val_loss=0.3557\n",
      "Epoch=231 loss=0.5665 val_loss=0.7837\n",
      "Epoch=232 loss=0.2706 val_loss=0.4269\n",
      "Epoch=233 loss=0.2705 val_loss=0.7822\n",
      "Epoch=234 loss=0.2802 val_loss=0.8433\n",
      "Epoch=235 loss=0.7412 val_loss=0.5393\n",
      "Epoch=236 loss=0.4803 val_loss=0.6545\n",
      "Epoch=237 loss=0.2505 val_loss=0.3316\n",
      "Epoch=238 loss=0.2010 val_loss=1.3036\n",
      "Epoch=239 loss=0.5144 val_loss=0.8265\n",
      "Epoch=240 loss=0.2857 val_loss=0.9401\n",
      "Epoch=241 loss=0.1701 val_loss=0.7507\n",
      "Epoch=242 loss=0.2675 val_loss=0.3106\n",
      "Epoch=243 loss=0.2178 val_loss=0.6960\n",
      "Epoch=244 loss=0.2462 val_loss=0.6563\n",
      "Epoch=245 loss=0.2071 val_loss=0.8745\n",
      "Epoch=246 loss=0.2695 val_loss=0.7477\n",
      "Epoch=247 loss=0.3260 val_loss=0.9322\n",
      "Epoch=248 loss=0.2695 val_loss=0.6543\n",
      "Epoch=249 loss=0.1793 val_loss=0.7672\n",
      "Epoch=250 loss=0.3062 val_loss=0.4148\n",
      "Epoch=251 loss=0.2250 val_loss=0.4983\n",
      "Epoch=252 loss=0.2729 val_loss=0.7256\n",
      "Epoch=253 loss=0.2016 val_loss=1.4826\n",
      "Epoch=254 loss=0.2005 val_loss=0.5745\n",
      "Epoch=255 loss=0.1415 val_loss=0.5239\n",
      "Epoch=256 loss=0.2308 val_loss=0.4986\n",
      "Epoch=257 loss=0.4172 val_loss=0.6762\n",
      "Epoch=258 loss=0.2112 val_loss=0.5661\n",
      "Epoch=259 loss=0.1475 val_loss=0.9046\n",
      "Epoch=260 loss=0.2109 val_loss=0.6518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=261 loss=0.2175 val_loss=0.4906\n",
      "Epoch=262 loss=0.3163 val_loss=0.5647\n",
      "Epoch=263 loss=0.2528 val_loss=0.6403\n",
      "Epoch=264 loss=0.2896 val_loss=0.5949\n",
      "Epoch=265 loss=0.2023 val_loss=0.8346\n",
      "Epoch=266 loss=0.3244 val_loss=1.3161\n",
      "Epoch=267 loss=0.4328 val_loss=0.4861\n",
      "Epoch=268 loss=0.2153 val_loss=0.8139\n",
      "Epoch=269 loss=0.2423 val_loss=1.9095\n",
      "Epoch=270 loss=0.3192 val_loss=0.5862\n",
      "Epoch=271 loss=0.2109 val_loss=1.0847\n",
      "Epoch=272 loss=0.2667 val_loss=0.8853\n",
      "Epoch=273 loss=0.3636 val_loss=0.8413\n",
      "Epoch=274 loss=0.2780 val_loss=0.6094\n",
      "Epoch=275 loss=0.1596 val_loss=0.6169\n",
      "Epoch=276 loss=0.1855 val_loss=0.7514\n",
      "Epoch=277 loss=0.1146 val_loss=0.4959\n",
      "Epoch=278 loss=0.2319 val_loss=0.5868\n",
      "Epoch=279 loss=0.2698 val_loss=0.5645\n",
      "Epoch=280 loss=0.2646 val_loss=0.4939\n",
      "Epoch=281 loss=0.1603 val_loss=0.1703\n",
      "Epoch=282 loss=0.1198 val_loss=0.5997\n",
      "Epoch=283 loss=0.1987 val_loss=0.5987\n",
      "Epoch=284 loss=0.1701 val_loss=0.5183\n",
      "Epoch=285 loss=0.1990 val_loss=0.8463\n",
      "Epoch=286 loss=0.1705 val_loss=0.5450\n",
      "Epoch=287 loss=0.1783 val_loss=1.5609\n",
      "Epoch=288 loss=0.1363 val_loss=0.7732\n",
      "Epoch=289 loss=0.1273 val_loss=0.6323\n",
      "Epoch=290 loss=0.1551 val_loss=0.4738\n",
      "Epoch=291 loss=0.2616 val_loss=0.2882\n",
      "Epoch=292 loss=0.1977 val_loss=0.4803\n",
      "Epoch=293 loss=0.2979 val_loss=0.2411\n",
      "Epoch=294 loss=0.1228 val_loss=0.5456\n",
      "Epoch=295 loss=0.1962 val_loss=0.5304\n",
      "Epoch=296 loss=0.1512 val_loss=0.8372\n",
      "Epoch=297 loss=0.2173 val_loss=0.2921\n",
      "Epoch=298 loss=0.1137 val_loss=0.4694\n",
      "Epoch=299 loss=0.1275 val_loss=0.4856\n",
      "Epoch=300 loss=0.2019 val_loss=0.3653\n",
      "Epoch=301 loss=0.2553 val_loss=0.5522\n",
      "Epoch=302 loss=0.4726 val_loss=0.8133\n",
      "Epoch=303 loss=0.1560 val_loss=0.4269\n",
      "Epoch=304 loss=0.2924 val_loss=0.3112\n",
      "Epoch=305 loss=0.2774 val_loss=1.2557\n",
      "Epoch=306 loss=0.3378 val_loss=1.4095\n",
      "Epoch=307 loss=0.2554 val_loss=1.0251\n",
      "Epoch=308 loss=0.2128 val_loss=0.4870\n",
      "Epoch=309 loss=0.3940 val_loss=0.4902\n",
      "Epoch=310 loss=0.1401 val_loss=0.6415\n",
      "Epoch=311 loss=0.2339 val_loss=0.2963\n",
      "Epoch=312 loss=0.1924 val_loss=0.6194\n",
      "Epoch=313 loss=0.2053 val_loss=0.8423\n",
      "Epoch=314 loss=0.2886 val_loss=0.3672\n",
      "Epoch=315 loss=0.2383 val_loss=0.4960\n",
      "Epoch=316 loss=0.2486 val_loss=0.6538\n",
      "Epoch=317 loss=0.2672 val_loss=0.6897\n",
      "Epoch=318 loss=0.1804 val_loss=1.5483\n",
      "Epoch=319 loss=0.5841 val_loss=1.0532\n",
      "Epoch=320 loss=0.3993 val_loss=0.9199\n",
      "Epoch=321 loss=0.3447 val_loss=0.5288\n",
      "Epoch=322 loss=0.2583 val_loss=1.2767\n",
      "Epoch=323 loss=0.1972 val_loss=2.0589\n",
      "Epoch=324 loss=0.1929 val_loss=0.8275\n",
      "Epoch=325 loss=0.1647 val_loss=0.9832\n",
      "Epoch=326 loss=0.1719 val_loss=0.2282\n",
      "Epoch=327 loss=0.1749 val_loss=0.6737\n",
      "Epoch=328 loss=0.3469 val_loss=0.7573\n",
      "Epoch=329 loss=0.2169 val_loss=1.5640\n",
      "Epoch=330 loss=0.3356 val_loss=0.3759\n",
      "Epoch=331 loss=0.1744 val_loss=1.4087\n",
      "Epoch=332 loss=0.1639 val_loss=1.2399\n",
      "Epoch=333 loss=0.1139 val_loss=0.3874\n",
      "Epoch=334 loss=0.2188 val_loss=0.4423\n",
      "Epoch=335 loss=0.1619 val_loss=0.6398\n",
      "Epoch=336 loss=0.3748 val_loss=0.5962\n",
      "Epoch=337 loss=0.2170 val_loss=0.4671\n",
      "Epoch=338 loss=0.2067 val_loss=0.4678\n",
      "Epoch=339 loss=0.1950 val_loss=0.8098\n",
      "Epoch=340 loss=0.1633 val_loss=0.8606\n",
      "Epoch=341 loss=0.1420 val_loss=0.5427\n",
      "Epoch=342 loss=0.1606 val_loss=1.1332\n",
      "Epoch=343 loss=0.2300 val_loss=0.4023\n",
      "Epoch=344 loss=0.2169 val_loss=0.5766\n",
      "Epoch=345 loss=0.1161 val_loss=0.3535\n",
      "Epoch=346 loss=0.3919 val_loss=0.3452\n",
      "Epoch=347 loss=0.3004 val_loss=0.5867\n",
      "Epoch=348 loss=0.1732 val_loss=0.6796\n",
      "Epoch=349 loss=0.2072 val_loss=0.4135\n",
      "Epoch=350 loss=0.2175 val_loss=0.4819\n",
      "Epoch=351 loss=0.1692 val_loss=0.6334\n",
      "Epoch=352 loss=0.1893 val_loss=0.4528\n",
      "Epoch=353 loss=0.2095 val_loss=0.1939\n",
      "Epoch=354 loss=0.2087 val_loss=0.7910\n",
      "Epoch=355 loss=0.1645 val_loss=0.5210\n",
      "Epoch=356 loss=0.1215 val_loss=0.6562\n",
      "Epoch=357 loss=0.1604 val_loss=1.2854\n",
      "Epoch=358 loss=0.1152 val_loss=0.4927\n",
      "Epoch=359 loss=0.3579 val_loss=1.4431\n",
      "Epoch=360 loss=0.1527 val_loss=0.4541\n",
      "Epoch=361 loss=0.3100 val_loss=0.4110\n",
      "Epoch=362 loss=0.2874 val_loss=0.4135\n",
      "Epoch=363 loss=0.2624 val_loss=0.9512\n",
      "Epoch=364 loss=0.1414 val_loss=0.7159\n",
      "Epoch=365 loss=0.1634 val_loss=0.5608\n",
      "Epoch=366 loss=0.3493 val_loss=0.8272\n",
      "Epoch=367 loss=0.1819 val_loss=0.6506\n",
      "Epoch=368 loss=0.1498 val_loss=0.5908\n",
      "Epoch=369 loss=0.2274 val_loss=0.6061\n",
      "Epoch=370 loss=0.1574 val_loss=0.4263\n",
      "Epoch=371 loss=0.1364 val_loss=0.4953\n",
      "Epoch=372 loss=0.2476 val_loss=0.8395\n",
      "Epoch=373 loss=0.1062 val_loss=0.4020\n",
      "Epoch=374 loss=0.1137 val_loss=0.6782\n",
      "Epoch=375 loss=0.2278 val_loss=0.7663\n",
      "Epoch=376 loss=0.1117 val_loss=0.3263\n",
      "Epoch=377 loss=0.1323 val_loss=0.7814\n",
      "Epoch=378 loss=0.1577 val_loss=1.0924\n",
      "Epoch=379 loss=0.1611 val_loss=0.6937\n",
      "Epoch=380 loss=0.2326 val_loss=0.5145\n",
      "Epoch=381 loss=0.1413 val_loss=0.5497\n",
      "Epoch=382 loss=0.1470 val_loss=1.7072\n",
      "Epoch=383 loss=0.1417 val_loss=0.9088\n",
      "Epoch=384 loss=0.1181 val_loss=0.5342\n",
      "Epoch=385 loss=0.1503 val_loss=0.5909\n",
      "Epoch=386 loss=0.1465 val_loss=0.5239\n",
      "Epoch=387 loss=0.1516 val_loss=0.5751\n",
      "Epoch=388 loss=0.1140 val_loss=0.2442\n",
      "Epoch=389 loss=0.1288 val_loss=0.3990\n",
      "Epoch=390 loss=0.0815 val_loss=1.0667\n",
      "Epoch=391 loss=0.1017 val_loss=1.4516\n",
      "Epoch=392 loss=0.1354 val_loss=0.3125\n",
      "Epoch=393 loss=0.1178 val_loss=0.5923\n",
      "Epoch=394 loss=0.1899 val_loss=1.4172\n",
      "Epoch=395 loss=0.1112 val_loss=1.9110\n",
      "Epoch=396 loss=0.1059 val_loss=0.4349\n",
      "Epoch=397 loss=0.1495 val_loss=0.2522\n",
      "Epoch=398 loss=0.1072 val_loss=0.3235\n",
      "Epoch=399 loss=0.1342 val_loss=0.2458\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "\n",
    "# Training\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "loss_function = torch.nn.MSELoss().cuda()\n",
    "optimizer = optim.Adam(N.parameters(), lr=0.001)\n",
    "\n",
    "test_stop = 100\n",
    "max_val_loss = 10000.0\n",
    "for epoch_step in range(0, 1000, test_stop):\n",
    "    if epoch_step!=0:\n",
    "        N = TwoLayerCNN()\n",
    "        optimizer = optim.Adam(N.parameters(), lr=0.001)\n",
    "\n",
    "        checkpoint = torch.load(path_to_out+'model.pth')\n",
    "        N.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        last_best_epoch = checkpoint['epoch']\n",
    "        loss = checkpoint['loss']\n",
    "        N.train()\n",
    "        \n",
    "        if last_best_epoch + test_stop > ep:\n",
    "            for ep in range(epoch_step, epoch_step+test_stop):\n",
    "                for _, data in enumerate(train_dataloader, 0): # get bacth\n",
    "                    inputs, labels = data # parse batch\n",
    "                    optimizer.zero_grad() # sets the gradients of all optimized tensors to zero.\n",
    "                    outputs = N(inputs) # get outputs\n",
    "                    loss = loss_function(outputs, labels) # calculate loss\n",
    "                    loss.backward() # calculate gradients\n",
    "                    optimizer.step() # performs a single optimization step (parameter update).\n",
    "\n",
    "                for specs, labels in validation_dataloader: val_loss = loss_function(N(specs),labels)\n",
    "                if val_loss.item() <= max_val_loss:\n",
    "                    torch.save({'epoch': ep,\n",
    "                                'model_state_dict': N.state_dict(),\n",
    "                                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                                'loss': loss}, path_to_out+'model.pth')\n",
    "                    max_val_loss = val_loss.item()\n",
    "                print(f\"Epoch={ep} loss={loss:.4f} val_loss={val_loss:.4f}\")\n",
    "        else: \n",
    "            continue \n",
    "\n",
    "    if epoch_step==0:\n",
    "        for ep in range(epoch_step, test_stop):\n",
    "            for _, data in enumerate(train_dataloader, 0): # get bacth\n",
    "                inputs, labels = data # parse batch\n",
    "                optimizer.zero_grad() # sets the gradients of all optimized tensors to zero.\n",
    "                outputs = N(inputs) # get outputs\n",
    "                loss = loss_function(outputs, labels) # calculate loss\n",
    "                loss.backward() # calculate gradients\n",
    "                optimizer.step() # performs a single optimization step (parameter update).\n",
    "            \n",
    "            for specs, labels in validation_dataloader: val_loss = loss_function(N(specs),labels)\n",
    "            if val_loss.item() <= max_val_loss:\n",
    "                torch.save({'epoch': ep,\n",
    "                            'model_state_dict': N.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'loss': loss}, path_to_out+'model.pth')\n",
    "                max_val_loss = val_loss.item()\n",
    "            print(f\"Epoch={ep} loss={loss:.4f}\")\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Statistics\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "N = TwoLayerCNN()\n",
    "optimizer = optim.Adam(N.parameters(), lr=0.001)\n",
    "\n",
    "checkpoint = torch.load(path_to_out+'model.pth')\n",
    "N.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "last_best_epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "N.eval()\n",
    "\n",
    "y_ae_test = np.zeros((1,4))\n",
    "for specs, labels in test_dataloader:\n",
    "    outputs = N(specs)\n",
    "    outputs[outputs<0]=0\n",
    "    ae = torch.abs(outputs-labels).detach().numpy()\n",
    "    np.concatenate((y_ae_test, ae), axis=0)\n",
    "    y_ae_test = np.concatenate((y_ae_test, ae), axis=0)\n",
    "    \n",
    "y_ae_trn = np.zeros((1,4))\n",
    "for specs, labels in train_dataloader:\n",
    "    outputs = N(specs)\n",
    "    outputs[outputs<0]=0\n",
    "    ae = torch.abs(outputs-labels).detach().numpy()\n",
    "    np.concatenate((y_ae_trn, ae), axis=0)\n",
    "    y_ae_trn = np.concatenate((y_ae_trn, ae), axis=0)\n",
    "    \n",
    "y_ae_vld = np.zeros((1,4))\n",
    "for specs, labels in validation_dataloader:\n",
    "    outputs = N(specs)\n",
    "    outputs[outputs<0]=0\n",
    "    ae = torch.abs(outputs-labels).detach().numpy()\n",
    "    np.concatenate((y_ae_vld, ae), axis=0)\n",
    "    y_ae_vld = np.concatenate((y_ae_vld, ae), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write Network's answers\n",
    "\n",
    "a = ['Cu','Ni','Cr','NO3']\n",
    "\n",
    "pd.DataFrame(y_ae_test).to_csv(path_to_out+ 'Y_out_tst.csv',sep=',', header = a)\n",
    "pd.DataFrame(y_ae_trn).to_csv(path_to_out + 'Y_out_trn.csv',sep=',', header = a)\n",
    "pd.DataFrame(y_ae_vld).to_csv(path_to_out + 'Y_out_vld.csv',sep=',', header = a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
