{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CD_HM_MLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "207cb99efbea4615ac6c056d4ed47db7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e3abdf64aa1944d9803322f6c58fcb71",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_33a3c7496e1641e28f43dffc9fa74dea",
              "IPY_MODEL_e238fca1861942aab478ba8d401f563e"
            ]
          }
        },
        "e3abdf64aa1944d9803322f6c58fcb71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33a3c7496e1641e28f43dffc9fa74dea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_e96d3c2a93164d6bb707174cc15e44ef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_12fde07b0ce04e2687468deb166b723f"
          }
        },
        "e238fca1861942aab478ba8d401f563e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eaad389041004134ae63bf6d8e25cb63",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff0cd83a2d434c4caa7b87552433416c"
          }
        },
        "e96d3c2a93164d6bb707174cc15e44ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "12fde07b0ce04e2687468deb166b723f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eaad389041004134ae63bf6d8e25cb63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff0cd83a2d434c4caa7b87552433416c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MufSlXaeAJU"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import median_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.model_selection import KFold\n",
        "import random\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1-tXmaXeE-_",
        "outputId": "8dba7e77-3850-4c34-d50e-3c1ad0153336"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtC0TOSgeGQP",
        "outputId": "0bf66e00-93fa-4a51-da53-894edbab0412"
      },
      "source": [
        "!unzip drive/My\\ Drive/NN_201_Sarmanova/full_data.zip #full_data.zip located in NN_201_Sarmanova folder at google drive."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  drive/My Drive/NN_201_Sarmanova/full_data.zip\n",
            "  inflating: full_data/1.csv         \n",
            "  inflating: full_data/10.csv        \n",
            "  inflating: full_data/100.csv       \n",
            "  inflating: full_data/1000.csv      \n",
            "  inflating: full_data/101.csv       \n",
            "  inflating: full_data/102.csv       \n",
            "  inflating: full_data/103.csv       \n",
            "  inflating: full_data/104.csv       \n",
            "  inflating: full_data/105.csv       \n",
            "  inflating: full_data/106.csv       \n",
            "  inflating: full_data/107.csv       \n",
            "  inflating: full_data/108.csv       \n",
            "  inflating: full_data/109.csv       \n",
            "  inflating: full_data/11.csv        \n",
            "  inflating: full_data/110.csv       \n",
            "  inflating: full_data/111.csv       \n",
            "  inflating: full_data/112.csv       \n",
            "  inflating: full_data/113.csv       \n",
            "  inflating: full_data/114.csv       \n",
            "  inflating: full_data/115.csv       \n",
            "  inflating: full_data/116.csv       \n",
            "  inflating: full_data/117.csv       \n",
            "  inflating: full_data/118.csv       \n",
            "  inflating: full_data/119.csv       \n",
            "  inflating: full_data/12.csv        \n",
            "  inflating: full_data/120.csv       \n",
            "  inflating: full_data/121.csv       \n",
            "  inflating: full_data/122.csv       \n",
            "  inflating: full_data/123.csv       \n",
            "  inflating: full_data/124.csv       \n",
            "  inflating: full_data/125.csv       \n",
            "  inflating: full_data/126.csv       \n",
            "  inflating: full_data/127.csv       \n",
            "  inflating: full_data/128.csv       \n",
            "  inflating: full_data/129.csv       \n",
            "  inflating: full_data/13.csv        \n",
            "  inflating: full_data/130.csv       \n",
            "  inflating: full_data/131.csv       \n",
            "  inflating: full_data/132.csv       \n",
            "  inflating: full_data/133.csv       \n",
            "  inflating: full_data/134.csv       \n",
            "  inflating: full_data/135.csv       \n",
            "  inflating: full_data/136.csv       \n",
            "  inflating: full_data/137.csv       \n",
            "  inflating: full_data/138.csv       \n",
            "  inflating: full_data/139.csv       \n",
            "  inflating: full_data/14.csv        \n",
            "  inflating: full_data/140.csv       \n",
            "  inflating: full_data/141.csv       \n",
            "  inflating: full_data/142.csv       \n",
            "  inflating: full_data/143.csv       \n",
            "  inflating: full_data/144.csv       \n",
            "  inflating: full_data/145.csv       \n",
            "  inflating: full_data/146.csv       \n",
            "  inflating: full_data/147.csv       \n",
            "  inflating: full_data/148.csv       \n",
            "  inflating: full_data/149.csv       \n",
            "  inflating: full_data/15.csv        \n",
            "  inflating: full_data/150.csv       \n",
            "  inflating: full_data/151.csv       \n",
            "  inflating: full_data/152.csv       \n",
            "  inflating: full_data/153.csv       \n",
            "  inflating: full_data/154.csv       \n",
            "  inflating: full_data/155.csv       \n",
            "  inflating: full_data/156.csv       \n",
            "  inflating: full_data/157.csv       \n",
            "  inflating: full_data/158.csv       \n",
            "  inflating: full_data/159.csv       \n",
            "  inflating: full_data/16.csv        \n",
            "  inflating: full_data/160.csv       \n",
            "  inflating: full_data/161.csv       \n",
            "  inflating: full_data/162.csv       \n",
            "  inflating: full_data/163.csv       \n",
            "  inflating: full_data/164.csv       \n",
            "  inflating: full_data/165.csv       \n",
            "  inflating: full_data/166.csv       \n",
            "  inflating: full_data/167.csv       \n",
            "  inflating: full_data/168.csv       \n",
            "  inflating: full_data/169.csv       \n",
            "  inflating: full_data/17.csv        \n",
            "  inflating: full_data/170.csv       \n",
            "  inflating: full_data/171.csv       \n",
            "  inflating: full_data/172.csv       \n",
            "  inflating: full_data/173.csv       \n",
            "  inflating: full_data/174.csv       \n",
            "  inflating: full_data/175.csv       \n",
            "  inflating: full_data/176.csv       \n",
            "  inflating: full_data/177.csv       \n",
            "  inflating: full_data/178.csv       \n",
            "  inflating: full_data/179.csv       \n",
            "  inflating: full_data/18.csv        \n",
            "  inflating: full_data/180.csv       \n",
            "  inflating: full_data/181.csv       \n",
            "  inflating: full_data/182.csv       \n",
            "  inflating: full_data/183.csv       \n",
            "  inflating: full_data/184.csv       \n",
            "  inflating: full_data/185.csv       \n",
            "  inflating: full_data/186.csv       \n",
            "  inflating: full_data/187.csv       \n",
            "  inflating: full_data/188.csv       \n",
            "  inflating: full_data/189.csv       \n",
            "  inflating: full_data/19.csv        \n",
            "  inflating: full_data/190.csv       \n",
            "  inflating: full_data/191.csv       \n",
            "  inflating: full_data/192.csv       \n",
            "  inflating: full_data/193.csv       \n",
            "  inflating: full_data/194.csv       \n",
            "  inflating: full_data/195.csv       \n",
            "  inflating: full_data/196.csv       \n",
            "  inflating: full_data/197.csv       \n",
            "  inflating: full_data/198.csv       \n",
            "  inflating: full_data/199.csv       \n",
            "  inflating: full_data/2.csv         \n",
            "  inflating: full_data/20.csv        \n",
            "  inflating: full_data/200.csv       \n",
            "  inflating: full_data/201.csv       \n",
            "  inflating: full_data/202.csv       \n",
            "  inflating: full_data/203.csv       \n",
            "  inflating: full_data/204.csv       \n",
            "  inflating: full_data/205.csv       \n",
            "  inflating: full_data/206.csv       \n",
            "  inflating: full_data/207.csv       \n",
            "  inflating: full_data/208.csv       \n",
            "  inflating: full_data/209.csv       \n",
            "  inflating: full_data/21.csv        \n",
            "  inflating: full_data/210.csv       \n",
            "  inflating: full_data/211.csv       \n",
            "  inflating: full_data/212.csv       \n",
            "  inflating: full_data/213.csv       \n",
            "  inflating: full_data/214.csv       \n",
            "  inflating: full_data/215.csv       \n",
            "  inflating: full_data/216.csv       \n",
            "  inflating: full_data/217.csv       \n",
            "  inflating: full_data/218.csv       \n",
            "  inflating: full_data/219.csv       \n",
            "  inflating: full_data/22.csv        \n",
            "  inflating: full_data/220.csv       \n",
            "  inflating: full_data/221.csv       \n",
            "  inflating: full_data/222.csv       \n",
            "  inflating: full_data/223.csv       \n",
            "  inflating: full_data/224.csv       \n",
            "  inflating: full_data/225.csv       \n",
            "  inflating: full_data/226.csv       \n",
            "  inflating: full_data/227.csv       \n",
            "  inflating: full_data/228.csv       \n",
            "  inflating: full_data/229.csv       \n",
            "  inflating: full_data/23.csv        \n",
            "  inflating: full_data/230.csv       \n",
            "  inflating: full_data/231.csv       \n",
            "  inflating: full_data/232.csv       \n",
            "  inflating: full_data/233.csv       \n",
            "  inflating: full_data/234.csv       \n",
            "  inflating: full_data/235.csv       \n",
            "  inflating: full_data/236.csv       \n",
            "  inflating: full_data/237.csv       \n",
            "  inflating: full_data/238.csv       \n",
            "  inflating: full_data/239.csv       \n",
            "  inflating: full_data/24.csv        \n",
            "  inflating: full_data/240.csv       \n",
            "  inflating: full_data/241.csv       \n",
            "  inflating: full_data/242.csv       \n",
            "  inflating: full_data/243.csv       \n",
            "  inflating: full_data/244.csv       \n",
            "  inflating: full_data/245.csv       \n",
            "  inflating: full_data/246.csv       \n",
            "  inflating: full_data/247.csv       \n",
            "  inflating: full_data/248.csv       \n",
            "  inflating: full_data/249.csv       \n",
            "  inflating: full_data/25.csv        \n",
            "  inflating: full_data/250.csv       \n",
            "  inflating: full_data/251.csv       \n",
            "  inflating: full_data/252.csv       \n",
            "  inflating: full_data/253.csv       \n",
            "  inflating: full_data/254.csv       \n",
            "  inflating: full_data/255.csv       \n",
            "  inflating: full_data/256.csv       \n",
            "  inflating: full_data/257.csv       \n",
            "  inflating: full_data/258.csv       \n",
            "  inflating: full_data/259.csv       \n",
            "  inflating: full_data/26.csv        \n",
            "  inflating: full_data/260.csv       \n",
            "  inflating: full_data/261.csv       \n",
            "  inflating: full_data/262.csv       \n",
            "  inflating: full_data/263.csv       \n",
            "  inflating: full_data/264.csv       \n",
            "  inflating: full_data/265.csv       \n",
            "  inflating: full_data/266.csv       \n",
            "  inflating: full_data/267.csv       \n",
            "  inflating: full_data/268.csv       \n",
            "  inflating: full_data/269.csv       \n",
            "  inflating: full_data/27.csv        \n",
            "  inflating: full_data/270.csv       \n",
            "  inflating: full_data/271.csv       \n",
            "  inflating: full_data/272.csv       \n",
            "  inflating: full_data/273.csv       \n",
            "  inflating: full_data/274.csv       \n",
            "  inflating: full_data/275.csv       \n",
            "  inflating: full_data/276.csv       \n",
            "  inflating: full_data/277.csv       \n",
            "  inflating: full_data/278.csv       \n",
            "  inflating: full_data/279.csv       \n",
            "  inflating: full_data/28.csv        \n",
            "  inflating: full_data/280.csv       \n",
            "  inflating: full_data/281.csv       \n",
            "  inflating: full_data/282.csv       \n",
            "  inflating: full_data/283.csv       \n",
            "  inflating: full_data/284.csv       \n",
            "  inflating: full_data/285.csv       \n",
            "  inflating: full_data/286.csv       \n",
            "  inflating: full_data/287.csv       \n",
            "  inflating: full_data/288.csv       \n",
            "  inflating: full_data/289.csv       \n",
            "  inflating: full_data/29.csv        \n",
            "  inflating: full_data/290.csv       \n",
            "  inflating: full_data/291.csv       \n",
            "  inflating: full_data/292.csv       \n",
            "  inflating: full_data/293.csv       \n",
            "  inflating: full_data/294.csv       \n",
            "  inflating: full_data/295.csv       \n",
            "  inflating: full_data/296.csv       \n",
            "  inflating: full_data/297.csv       \n",
            "  inflating: full_data/298.csv       \n",
            "  inflating: full_data/299.csv       \n",
            "  inflating: full_data/3.csv         \n",
            "  inflating: full_data/30.csv        \n",
            "  inflating: full_data/300.csv       \n",
            "  inflating: full_data/301.csv       \n",
            "  inflating: full_data/302.csv       \n",
            "  inflating: full_data/303.csv       \n",
            "  inflating: full_data/304.csv       \n",
            "  inflating: full_data/305.csv       \n",
            "  inflating: full_data/306.csv       \n",
            "  inflating: full_data/307.csv       \n",
            "  inflating: full_data/308.csv       \n",
            "  inflating: full_data/309.csv       \n",
            "  inflating: full_data/31.csv        \n",
            "  inflating: full_data/310.csv       \n",
            "  inflating: full_data/311.csv       \n",
            "  inflating: full_data/312.csv       \n",
            "  inflating: full_data/313.csv       \n",
            "  inflating: full_data/314.csv       \n",
            "  inflating: full_data/315.csv       \n",
            "  inflating: full_data/316.csv       \n",
            "  inflating: full_data/317.csv       \n",
            "  inflating: full_data/318.csv       \n",
            "  inflating: full_data/319.csv       \n",
            "  inflating: full_data/32.csv        \n",
            "  inflating: full_data/320.csv       \n",
            "  inflating: full_data/321.csv       \n",
            "  inflating: full_data/322.csv       \n",
            "  inflating: full_data/323.csv       \n",
            "  inflating: full_data/324.csv       \n",
            "  inflating: full_data/325.csv       \n",
            "  inflating: full_data/326.csv       \n",
            "  inflating: full_data/327.csv       \n",
            "  inflating: full_data/328.csv       \n",
            "  inflating: full_data/329.csv       \n",
            "  inflating: full_data/33.csv        \n",
            "  inflating: full_data/330.csv       \n",
            "  inflating: full_data/331.csv       \n",
            "  inflating: full_data/332.csv       \n",
            "  inflating: full_data/333.csv       \n",
            "  inflating: full_data/334.csv       \n",
            "  inflating: full_data/335.csv       \n",
            "  inflating: full_data/336.csv       \n",
            "  inflating: full_data/337.csv       \n",
            "  inflating: full_data/338.csv       \n",
            "  inflating: full_data/339.csv       \n",
            "  inflating: full_data/34.csv        \n",
            "  inflating: full_data/340.csv       \n",
            "  inflating: full_data/341.csv       \n",
            "  inflating: full_data/342.csv       \n",
            "  inflating: full_data/343.csv       \n",
            "  inflating: full_data/344.csv       \n",
            "  inflating: full_data/345.csv       \n",
            "  inflating: full_data/346.csv       \n",
            "  inflating: full_data/347.csv       \n",
            "  inflating: full_data/348.csv       \n",
            "  inflating: full_data/349.csv       \n",
            "  inflating: full_data/35.csv        \n",
            "  inflating: full_data/350.csv       \n",
            "  inflating: full_data/351.csv       \n",
            "  inflating: full_data/352.csv       \n",
            "  inflating: full_data/353.csv       \n",
            "  inflating: full_data/354.csv       \n",
            "  inflating: full_data/355.csv       \n",
            "  inflating: full_data/356.csv       \n",
            "  inflating: full_data/357.csv       \n",
            "  inflating: full_data/358.csv       \n",
            "  inflating: full_data/359.csv       \n",
            "  inflating: full_data/36.csv        \n",
            "  inflating: full_data/360.csv       \n",
            "  inflating: full_data/361.csv       \n",
            "  inflating: full_data/362.csv       \n",
            "  inflating: full_data/363.csv       \n",
            "  inflating: full_data/364.csv       \n",
            "  inflating: full_data/365.csv       \n",
            "  inflating: full_data/366.csv       \n",
            "  inflating: full_data/367.csv       \n",
            "  inflating: full_data/368.csv       \n",
            "  inflating: full_data/369.csv       \n",
            "  inflating: full_data/37.csv        \n",
            "  inflating: full_data/370.csv       \n",
            "  inflating: full_data/371.csv       \n",
            "  inflating: full_data/372.csv       \n",
            "  inflating: full_data/373.csv       \n",
            "  inflating: full_data/374.csv       \n",
            "  inflating: full_data/375.csv       \n",
            "  inflating: full_data/376.csv       \n",
            "  inflating: full_data/377.csv       \n",
            "  inflating: full_data/378.csv       \n",
            "  inflating: full_data/379.csv       \n",
            "  inflating: full_data/38.csv        \n",
            "  inflating: full_data/380.csv       \n",
            "  inflating: full_data/381.csv       \n",
            "  inflating: full_data/382.csv       \n",
            "  inflating: full_data/383.csv       \n",
            "  inflating: full_data/384.csv       \n",
            "  inflating: full_data/385.csv       \n",
            "  inflating: full_data/386.csv       \n",
            "  inflating: full_data/387.csv       \n",
            "  inflating: full_data/388.csv       \n",
            "  inflating: full_data/389.csv       \n",
            "  inflating: full_data/39.csv        \n",
            "  inflating: full_data/390.csv       \n",
            "  inflating: full_data/391.csv       \n",
            "  inflating: full_data/392.csv       \n",
            "  inflating: full_data/393.csv       \n",
            "  inflating: full_data/394.csv       \n",
            "  inflating: full_data/395.csv       \n",
            "  inflating: full_data/396.csv       \n",
            "  inflating: full_data/397.csv       \n",
            "  inflating: full_data/398.csv       \n",
            "  inflating: full_data/399.csv       \n",
            "  inflating: full_data/4.csv         \n",
            "  inflating: full_data/40.csv        \n",
            "  inflating: full_data/400.csv       \n",
            "  inflating: full_data/401.csv       \n",
            "  inflating: full_data/402.csv       \n",
            "  inflating: full_data/403.csv       \n",
            "  inflating: full_data/404.csv       \n",
            "  inflating: full_data/405.csv       \n",
            "  inflating: full_data/406.csv       \n",
            "  inflating: full_data/407.csv       \n",
            "  inflating: full_data/408.csv       \n",
            "  inflating: full_data/409.csv       \n",
            "  inflating: full_data/41.csv        \n",
            "  inflating: full_data/410.csv       \n",
            "  inflating: full_data/411.csv       \n",
            "  inflating: full_data/412.csv       \n",
            "  inflating: full_data/413.csv       \n",
            "  inflating: full_data/414.csv       \n",
            "  inflating: full_data/415.csv       \n",
            "  inflating: full_data/416.csv       \n",
            "  inflating: full_data/417.csv       \n",
            "  inflating: full_data/418.csv       \n",
            "  inflating: full_data/419.csv       \n",
            "  inflating: full_data/42.csv        \n",
            "  inflating: full_data/420.csv       \n",
            "  inflating: full_data/421.csv       \n",
            "  inflating: full_data/422.csv       \n",
            "  inflating: full_data/423.csv       \n",
            "  inflating: full_data/424.csv       \n",
            "  inflating: full_data/425.csv       \n",
            "  inflating: full_data/426.csv       \n",
            "  inflating: full_data/427.csv       \n",
            "  inflating: full_data/428.csv       \n",
            "  inflating: full_data/429.csv       \n",
            "  inflating: full_data/43.csv        \n",
            "  inflating: full_data/430.csv       \n",
            "  inflating: full_data/431.csv       \n",
            "  inflating: full_data/432.csv       \n",
            "  inflating: full_data/433.csv       \n",
            "  inflating: full_data/434.csv       \n",
            "  inflating: full_data/435.csv       \n",
            "  inflating: full_data/436.csv       \n",
            "  inflating: full_data/437.csv       \n",
            "  inflating: full_data/438.csv       \n",
            "  inflating: full_data/439.csv       \n",
            "  inflating: full_data/44.csv        \n",
            "  inflating: full_data/440.csv       \n",
            "  inflating: full_data/441.csv       \n",
            "  inflating: full_data/442.csv       \n",
            "  inflating: full_data/443.csv       \n",
            "  inflating: full_data/444.csv       \n",
            "  inflating: full_data/445.csv       \n",
            "  inflating: full_data/446.csv       \n",
            "  inflating: full_data/447.csv       \n",
            "  inflating: full_data/448.csv       \n",
            "  inflating: full_data/449.csv       \n",
            "  inflating: full_data/45.csv        \n",
            "  inflating: full_data/450.csv       \n",
            "  inflating: full_data/451.csv       \n",
            "  inflating: full_data/452.csv       \n",
            "  inflating: full_data/453.csv       \n",
            "  inflating: full_data/454.csv       \n",
            "  inflating: full_data/455.csv       \n",
            "  inflating: full_data/456.csv       \n",
            "  inflating: full_data/457.csv       \n",
            "  inflating: full_data/458.csv       \n",
            "  inflating: full_data/459.csv       \n",
            "  inflating: full_data/46.csv        \n",
            "  inflating: full_data/460.csv       \n",
            "  inflating: full_data/461.csv       \n",
            "  inflating: full_data/462.csv       \n",
            "  inflating: full_data/463.csv       \n",
            "  inflating: full_data/464.csv       \n",
            "  inflating: full_data/465.csv       \n",
            "  inflating: full_data/466.csv       \n",
            "  inflating: full_data/467.csv       \n",
            "  inflating: full_data/468.csv       \n",
            "  inflating: full_data/469.csv       \n",
            "  inflating: full_data/47.csv        \n",
            "  inflating: full_data/470.csv       \n",
            "  inflating: full_data/471.csv       \n",
            "  inflating: full_data/472.csv       \n",
            "  inflating: full_data/473.csv       \n",
            "  inflating: full_data/474.csv       \n",
            "  inflating: full_data/475.csv       \n",
            "  inflating: full_data/476.csv       \n",
            "  inflating: full_data/477.csv       \n",
            "  inflating: full_data/478.csv       \n",
            "  inflating: full_data/479.csv       \n",
            "  inflating: full_data/48.csv        \n",
            "  inflating: full_data/480.csv       \n",
            "  inflating: full_data/481.csv       \n",
            "  inflating: full_data/482.csv       \n",
            "  inflating: full_data/483.csv       \n",
            "  inflating: full_data/484.csv       \n",
            "  inflating: full_data/485.csv       \n",
            "  inflating: full_data/486.csv       \n",
            "  inflating: full_data/487.csv       \n",
            "  inflating: full_data/488.csv       \n",
            "  inflating: full_data/489.csv       \n",
            "  inflating: full_data/49.csv        \n",
            "  inflating: full_data/490.csv       \n",
            "  inflating: full_data/491.csv       \n",
            "  inflating: full_data/492.csv       \n",
            "  inflating: full_data/493.csv       \n",
            "  inflating: full_data/494.csv       \n",
            "  inflating: full_data/495.csv       \n",
            "  inflating: full_data/496.csv       \n",
            "  inflating: full_data/497.csv       \n",
            "  inflating: full_data/498.csv       \n",
            "  inflating: full_data/499.csv       \n",
            "  inflating: full_data/5.csv         \n",
            "  inflating: full_data/50.csv        \n",
            "  inflating: full_data/500.csv       \n",
            "  inflating: full_data/501.csv       \n",
            "  inflating: full_data/502.csv       \n",
            "  inflating: full_data/503.csv       \n",
            "  inflating: full_data/504.csv       \n",
            "  inflating: full_data/505.csv       \n",
            "  inflating: full_data/506.csv       \n",
            "  inflating: full_data/507.csv       \n",
            "  inflating: full_data/508.csv       \n",
            "  inflating: full_data/509.csv       \n",
            "  inflating: full_data/51.csv        \n",
            "  inflating: full_data/510.csv       \n",
            "  inflating: full_data/511.csv       \n",
            "  inflating: full_data/512.csv       \n",
            "  inflating: full_data/513.csv       \n",
            "  inflating: full_data/514.csv       \n",
            "  inflating: full_data/515.csv       \n",
            "  inflating: full_data/516.csv       \n",
            "  inflating: full_data/517.csv       \n",
            "  inflating: full_data/518.csv       \n",
            "  inflating: full_data/519.csv       \n",
            "  inflating: full_data/52.csv        \n",
            "  inflating: full_data/520.csv       \n",
            "  inflating: full_data/521.csv       \n",
            "  inflating: full_data/522.csv       \n",
            "  inflating: full_data/523.csv       \n",
            "  inflating: full_data/524.csv       \n",
            "  inflating: full_data/525.csv       \n",
            "  inflating: full_data/526.csv       \n",
            "  inflating: full_data/527.csv       \n",
            "  inflating: full_data/528.csv       \n",
            "  inflating: full_data/529.csv       \n",
            "  inflating: full_data/53.csv        \n",
            "  inflating: full_data/530.csv       \n",
            "  inflating: full_data/531.csv       \n",
            "  inflating: full_data/532.csv       \n",
            "  inflating: full_data/533.csv       \n",
            "  inflating: full_data/534.csv       \n",
            "  inflating: full_data/535.csv       \n",
            "  inflating: full_data/536.csv       \n",
            "  inflating: full_data/537.csv       \n",
            "  inflating: full_data/538.csv       \n",
            "  inflating: full_data/539.csv       \n",
            "  inflating: full_data/54.csv        \n",
            "  inflating: full_data/540.csv       \n",
            "  inflating: full_data/541.csv       \n",
            "  inflating: full_data/542.csv       \n",
            "  inflating: full_data/543.csv       \n",
            "  inflating: full_data/544.csv       \n",
            "  inflating: full_data/545.csv       \n",
            "  inflating: full_data/546.csv       \n",
            "  inflating: full_data/547.csv       \n",
            "  inflating: full_data/548.csv       \n",
            "  inflating: full_data/549.csv       \n",
            "  inflating: full_data/55.csv        \n",
            "  inflating: full_data/550.csv       \n",
            "  inflating: full_data/551.csv       \n",
            "  inflating: full_data/552.csv       \n",
            "  inflating: full_data/553.csv       \n",
            "  inflating: full_data/554.csv       \n",
            "  inflating: full_data/555.csv       \n",
            "  inflating: full_data/556.csv       \n",
            "  inflating: full_data/557.csv       \n",
            "  inflating: full_data/558.csv       \n",
            "  inflating: full_data/559.csv       \n",
            "  inflating: full_data/56.csv        \n",
            "  inflating: full_data/560.csv       \n",
            "  inflating: full_data/561.csv       \n",
            "  inflating: full_data/562.csv       \n",
            "  inflating: full_data/563.csv       \n",
            "  inflating: full_data/564.csv       \n",
            "  inflating: full_data/565.csv       \n",
            "  inflating: full_data/566.csv       \n",
            "  inflating: full_data/567.csv       \n",
            "  inflating: full_data/568.csv       \n",
            "  inflating: full_data/569.csv       \n",
            "  inflating: full_data/57.csv        \n",
            "  inflating: full_data/570.csv       \n",
            "  inflating: full_data/571.csv       \n",
            "  inflating: full_data/572.csv       \n",
            "  inflating: full_data/573.csv       \n",
            "  inflating: full_data/574.csv       \n",
            "  inflating: full_data/575.csv       \n",
            "  inflating: full_data/576.csv       \n",
            "  inflating: full_data/577.csv       \n",
            "  inflating: full_data/578.csv       \n",
            "  inflating: full_data/579.csv       \n",
            "  inflating: full_data/58.csv        \n",
            "  inflating: full_data/580.csv       \n",
            "  inflating: full_data/581.csv       \n",
            "  inflating: full_data/582.csv       \n",
            "  inflating: full_data/583.csv       \n",
            "  inflating: full_data/584.csv       \n",
            "  inflating: full_data/585.csv       \n",
            "  inflating: full_data/586.csv       \n",
            "  inflating: full_data/587.csv       \n",
            "  inflating: full_data/588.csv       \n",
            "  inflating: full_data/589.csv       \n",
            "  inflating: full_data/59.csv        \n",
            "  inflating: full_data/590.csv       \n",
            "  inflating: full_data/591.csv       \n",
            "  inflating: full_data/592.csv       \n",
            "  inflating: full_data/593.csv       \n",
            "  inflating: full_data/594.csv       \n",
            "  inflating: full_data/595.csv       \n",
            "  inflating: full_data/596.csv       \n",
            "  inflating: full_data/597.csv       \n",
            "  inflating: full_data/598.csv       \n",
            "  inflating: full_data/599.csv       \n",
            "  inflating: full_data/6.csv         \n",
            "  inflating: full_data/60.csv        \n",
            "  inflating: full_data/600.csv       \n",
            "  inflating: full_data/601.csv       \n",
            "  inflating: full_data/602.csv       \n",
            "  inflating: full_data/603.csv       \n",
            "  inflating: full_data/604.csv       \n",
            "  inflating: full_data/605.csv       \n",
            "  inflating: full_data/606.csv       \n",
            "  inflating: full_data/607.csv       \n",
            "  inflating: full_data/608.csv       \n",
            "  inflating: full_data/609.csv       \n",
            "  inflating: full_data/61.csv        \n",
            "  inflating: full_data/610.csv       \n",
            "  inflating: full_data/611.csv       \n",
            "  inflating: full_data/612.csv       \n",
            "  inflating: full_data/613.csv       \n",
            "  inflating: full_data/614.csv       \n",
            "  inflating: full_data/615.csv       \n",
            "  inflating: full_data/616.csv       \n",
            "  inflating: full_data/617.csv       \n",
            "  inflating: full_data/618.csv       \n",
            "  inflating: full_data/619.csv       \n",
            "  inflating: full_data/62.csv        \n",
            "  inflating: full_data/620.csv       \n",
            "  inflating: full_data/621.csv       \n",
            "  inflating: full_data/622.csv       \n",
            "  inflating: full_data/623.csv       \n",
            "  inflating: full_data/624.csv       \n",
            "  inflating: full_data/625.csv       \n",
            "  inflating: full_data/626.csv       \n",
            "  inflating: full_data/627.csv       \n",
            "  inflating: full_data/628.csv       \n",
            "  inflating: full_data/629.csv       \n",
            "  inflating: full_data/63.csv        \n",
            "  inflating: full_data/630.csv       \n",
            "  inflating: full_data/631.csv       \n",
            "  inflating: full_data/632.csv       \n",
            "  inflating: full_data/633.csv       \n",
            "  inflating: full_data/634.csv       \n",
            "  inflating: full_data/635.csv       \n",
            "  inflating: full_data/636.csv       \n",
            "  inflating: full_data/637.csv       \n",
            "  inflating: full_data/638.csv       \n",
            "  inflating: full_data/639.csv       \n",
            "  inflating: full_data/64.csv        \n",
            "  inflating: full_data/640.csv       \n",
            "  inflating: full_data/641.csv       \n",
            "  inflating: full_data/642.csv       \n",
            "  inflating: full_data/643.csv       \n",
            "  inflating: full_data/644.csv       \n",
            "  inflating: full_data/645.csv       \n",
            "  inflating: full_data/646.csv       \n",
            "  inflating: full_data/647.csv       \n",
            "  inflating: full_data/648.csv       \n",
            "  inflating: full_data/649.csv       \n",
            "  inflating: full_data/65.csv        \n",
            "  inflating: full_data/650.csv       \n",
            "  inflating: full_data/651.csv       \n",
            "  inflating: full_data/652.csv       \n",
            "  inflating: full_data/653.csv       \n",
            "  inflating: full_data/654.csv       \n",
            "  inflating: full_data/655.csv       \n",
            "  inflating: full_data/656.csv       \n",
            "  inflating: full_data/657.csv       \n",
            "  inflating: full_data/658.csv       \n",
            "  inflating: full_data/659.csv       \n",
            "  inflating: full_data/66.csv        \n",
            "  inflating: full_data/660.csv       \n",
            "  inflating: full_data/661.csv       \n",
            "  inflating: full_data/662.csv       \n",
            "  inflating: full_data/663.csv       \n",
            "  inflating: full_data/664.csv       \n",
            "  inflating: full_data/665.csv       \n",
            "  inflating: full_data/666.csv       \n",
            "  inflating: full_data/667.csv       \n",
            "  inflating: full_data/668.csv       \n",
            "  inflating: full_data/669.csv       \n",
            "  inflating: full_data/67.csv        \n",
            "  inflating: full_data/670.csv       \n",
            "  inflating: full_data/671.csv       \n",
            "  inflating: full_data/672.csv       \n",
            "  inflating: full_data/673.csv       \n",
            "  inflating: full_data/674.csv       \n",
            "  inflating: full_data/675.csv       \n",
            "  inflating: full_data/676.csv       \n",
            "  inflating: full_data/677.csv       \n",
            "  inflating: full_data/678.csv       \n",
            "  inflating: full_data/679.csv       \n",
            "  inflating: full_data/68.csv        \n",
            "  inflating: full_data/680.csv       \n",
            "  inflating: full_data/681.csv       \n",
            "  inflating: full_data/682.csv       \n",
            "  inflating: full_data/683.csv       \n",
            "  inflating: full_data/684.csv       \n",
            "  inflating: full_data/685.csv       \n",
            "  inflating: full_data/686.csv       \n",
            "  inflating: full_data/687.csv       \n",
            "  inflating: full_data/688.csv       \n",
            "  inflating: full_data/689.csv       \n",
            "  inflating: full_data/69.csv        \n",
            "  inflating: full_data/690.csv       \n",
            "  inflating: full_data/691.csv       \n",
            "  inflating: full_data/692.csv       \n",
            "  inflating: full_data/693.csv       \n",
            "  inflating: full_data/694.csv       \n",
            "  inflating: full_data/695.csv       \n",
            "  inflating: full_data/696.csv       \n",
            "  inflating: full_data/697.csv       \n",
            "  inflating: full_data/698.csv       \n",
            "  inflating: full_data/699.csv       \n",
            "  inflating: full_data/7.csv         \n",
            "  inflating: full_data/70.csv        \n",
            "  inflating: full_data/700.csv       \n",
            "  inflating: full_data/701.csv       \n",
            "  inflating: full_data/702.csv       \n",
            "  inflating: full_data/703.csv       \n",
            "  inflating: full_data/704.csv       \n",
            "  inflating: full_data/705.csv       \n",
            "  inflating: full_data/706.csv       \n",
            "  inflating: full_data/707.csv       \n",
            "  inflating: full_data/708.csv       \n",
            "  inflating: full_data/709.csv       \n",
            "  inflating: full_data/71.csv        \n",
            "  inflating: full_data/710.csv       \n",
            "  inflating: full_data/711.csv       \n",
            "  inflating: full_data/712.csv       \n",
            "  inflating: full_data/713.csv       \n",
            "  inflating: full_data/714.csv       \n",
            "  inflating: full_data/715.csv       \n",
            "  inflating: full_data/716.csv       \n",
            "  inflating: full_data/717.csv       \n",
            "  inflating: full_data/718.csv       \n",
            "  inflating: full_data/719.csv       \n",
            "  inflating: full_data/72.csv        \n",
            "  inflating: full_data/720.csv       \n",
            "  inflating: full_data/721.csv       \n",
            "  inflating: full_data/722.csv       \n",
            "  inflating: full_data/723.csv       \n",
            "  inflating: full_data/724.csv       \n",
            "  inflating: full_data/725.csv       \n",
            "  inflating: full_data/726.csv       \n",
            "  inflating: full_data/727.csv       \n",
            "  inflating: full_data/728.csv       \n",
            "  inflating: full_data/729.csv       \n",
            "  inflating: full_data/73.csv        \n",
            "  inflating: full_data/730.csv       \n",
            "  inflating: full_data/731.csv       \n",
            "  inflating: full_data/732.csv       \n",
            "  inflating: full_data/733.csv       \n",
            "  inflating: full_data/734.csv       \n",
            "  inflating: full_data/735.csv       \n",
            "  inflating: full_data/736.csv       \n",
            "  inflating: full_data/737.csv       \n",
            "  inflating: full_data/738.csv       \n",
            "  inflating: full_data/739.csv       \n",
            "  inflating: full_data/74.csv        \n",
            "  inflating: full_data/740.csv       \n",
            "  inflating: full_data/741.csv       \n",
            "  inflating: full_data/742.csv       \n",
            "  inflating: full_data/743.csv       \n",
            "  inflating: full_data/744.csv       \n",
            "  inflating: full_data/745.csv       \n",
            "  inflating: full_data/746.csv       \n",
            "  inflating: full_data/747.csv       \n",
            "  inflating: full_data/748.csv       \n",
            "  inflating: full_data/749.csv       \n",
            "  inflating: full_data/75.csv        \n",
            "  inflating: full_data/750.csv       \n",
            "  inflating: full_data/751.csv       \n",
            "  inflating: full_data/752.csv       \n",
            "  inflating: full_data/753.csv       \n",
            "  inflating: full_data/754.csv       \n",
            "  inflating: full_data/755.csv       \n",
            "  inflating: full_data/756.csv       \n",
            "  inflating: full_data/757.csv       \n",
            "  inflating: full_data/758.csv       \n",
            "  inflating: full_data/759.csv       \n",
            "  inflating: full_data/76.csv        \n",
            "  inflating: full_data/760.csv       \n",
            "  inflating: full_data/761.csv       \n",
            "  inflating: full_data/762.csv       \n",
            "  inflating: full_data/763.csv       \n",
            "  inflating: full_data/764.csv       \n",
            "  inflating: full_data/765.csv       \n",
            "  inflating: full_data/766.csv       \n",
            "  inflating: full_data/767.csv       \n",
            "  inflating: full_data/768.csv       \n",
            "  inflating: full_data/769.csv       \n",
            "  inflating: full_data/77.csv        \n",
            "  inflating: full_data/770.csv       \n",
            "  inflating: full_data/771.csv       \n",
            "  inflating: full_data/772.csv       \n",
            "  inflating: full_data/773.csv       \n",
            "  inflating: full_data/774.csv       \n",
            "  inflating: full_data/775.csv       \n",
            "  inflating: full_data/776.csv       \n",
            "  inflating: full_data/777.csv       \n",
            "  inflating: full_data/778.csv       \n",
            "  inflating: full_data/779.csv       \n",
            "  inflating: full_data/78.csv        \n",
            "  inflating: full_data/780.csv       \n",
            "  inflating: full_data/781.csv       \n",
            "  inflating: full_data/782.csv       \n",
            "  inflating: full_data/783.csv       \n",
            "  inflating: full_data/784.csv       \n",
            "  inflating: full_data/785.csv       \n",
            "  inflating: full_data/786.csv       \n",
            "  inflating: full_data/787.csv       \n",
            "  inflating: full_data/788.csv       \n",
            "  inflating: full_data/789.csv       \n",
            "  inflating: full_data/79.csv        \n",
            "  inflating: full_data/790.csv       \n",
            "  inflating: full_data/791.csv       \n",
            "  inflating: full_data/792.csv       \n",
            "  inflating: full_data/793.csv       \n",
            "  inflating: full_data/794.csv       \n",
            "  inflating: full_data/795.csv       \n",
            "  inflating: full_data/796.csv       \n",
            "  inflating: full_data/797.csv       \n",
            "  inflating: full_data/798.csv       \n",
            "  inflating: full_data/799.csv       \n",
            "  inflating: full_data/8.csv         \n",
            "  inflating: full_data/80.csv        \n",
            "  inflating: full_data/800.csv       \n",
            "  inflating: full_data/801.csv       \n",
            "  inflating: full_data/802.csv       \n",
            "  inflating: full_data/803.csv       \n",
            "  inflating: full_data/804.csv       \n",
            "  inflating: full_data/805.csv       \n",
            "  inflating: full_data/806.csv       \n",
            "  inflating: full_data/807.csv       \n",
            "  inflating: full_data/808.csv       \n",
            "  inflating: full_data/809.csv       \n",
            "  inflating: full_data/81.csv        \n",
            "  inflating: full_data/810.csv       \n",
            "  inflating: full_data/811.csv       \n",
            "  inflating: full_data/812.csv       \n",
            "  inflating: full_data/813.csv       \n",
            "  inflating: full_data/814.csv       \n",
            "  inflating: full_data/815.csv       \n",
            "  inflating: full_data/816.csv       \n",
            "  inflating: full_data/817.csv       \n",
            "  inflating: full_data/818.csv       \n",
            "  inflating: full_data/819.csv       \n",
            "  inflating: full_data/82.csv        \n",
            "  inflating: full_data/820.csv       \n",
            "  inflating: full_data/821.csv       \n",
            "  inflating: full_data/822.csv       \n",
            "  inflating: full_data/823.csv       \n",
            "  inflating: full_data/824.csv       \n",
            "  inflating: full_data/825.csv       \n",
            "  inflating: full_data/826.csv       \n",
            "  inflating: full_data/827.csv       \n",
            "  inflating: full_data/828.csv       \n",
            "  inflating: full_data/829.csv       \n",
            "  inflating: full_data/83.csv        \n",
            "  inflating: full_data/830.csv       \n",
            "  inflating: full_data/831.csv       \n",
            "  inflating: full_data/832.csv       \n",
            "  inflating: full_data/833.csv       \n",
            "  inflating: full_data/834.csv       \n",
            "  inflating: full_data/835.csv       \n",
            "  inflating: full_data/836.csv       \n",
            "  inflating: full_data/837.csv       \n",
            "  inflating: full_data/838.csv       \n",
            "  inflating: full_data/839.csv       \n",
            "  inflating: full_data/84.csv        \n",
            "  inflating: full_data/840.csv       \n",
            "  inflating: full_data/841.csv       \n",
            "  inflating: full_data/842.csv       \n",
            "  inflating: full_data/843.csv       \n",
            "  inflating: full_data/844.csv       \n",
            "  inflating: full_data/845.csv       \n",
            "  inflating: full_data/846.csv       \n",
            "  inflating: full_data/847.csv       \n",
            "  inflating: full_data/848.csv       \n",
            "  inflating: full_data/849.csv       \n",
            "  inflating: full_data/85.csv        \n",
            "  inflating: full_data/850.csv       \n",
            "  inflating: full_data/851.csv       \n",
            "  inflating: full_data/852.csv       \n",
            "  inflating: full_data/853.csv       \n",
            "  inflating: full_data/854.csv       \n",
            "  inflating: full_data/855.csv       \n",
            "  inflating: full_data/856.csv       \n",
            "  inflating: full_data/857.csv       \n",
            "  inflating: full_data/858.csv       \n",
            "  inflating: full_data/859.csv       \n",
            "  inflating: full_data/86.csv        \n",
            "  inflating: full_data/860.csv       \n",
            "  inflating: full_data/861.csv       \n",
            "  inflating: full_data/862.csv       \n",
            "  inflating: full_data/863.csv       \n",
            "  inflating: full_data/864.csv       \n",
            "  inflating: full_data/865.csv       \n",
            "  inflating: full_data/866.csv       \n",
            "  inflating: full_data/867.csv       \n",
            "  inflating: full_data/868.csv       \n",
            "  inflating: full_data/869.csv       \n",
            "  inflating: full_data/87.csv        \n",
            "  inflating: full_data/870.csv       \n",
            "  inflating: full_data/871.csv       \n",
            "  inflating: full_data/872.csv       \n",
            "  inflating: full_data/873.csv       \n",
            "  inflating: full_data/874.csv       \n",
            "  inflating: full_data/875.csv       \n",
            "  inflating: full_data/876.csv       \n",
            "  inflating: full_data/877.csv       \n",
            "  inflating: full_data/878.csv       \n",
            "  inflating: full_data/879.csv       \n",
            "  inflating: full_data/88.csv        \n",
            "  inflating: full_data/880.csv       \n",
            "  inflating: full_data/881.csv       \n",
            "  inflating: full_data/882.csv       \n",
            "  inflating: full_data/883.csv       \n",
            "  inflating: full_data/884.csv       \n",
            "  inflating: full_data/885.csv       \n",
            "  inflating: full_data/886.csv       \n",
            "  inflating: full_data/887.csv       \n",
            "  inflating: full_data/888.csv       \n",
            "  inflating: full_data/889.csv       \n",
            "  inflating: full_data/89.csv        \n",
            "  inflating: full_data/890.csv       \n",
            "  inflating: full_data/891.csv       \n",
            "  inflating: full_data/892.csv       \n",
            "  inflating: full_data/893.csv       \n",
            "  inflating: full_data/894.csv       \n",
            "  inflating: full_data/895.csv       \n",
            "  inflating: full_data/896.csv       \n",
            "  inflating: full_data/897.csv       \n",
            "  inflating: full_data/898.csv       \n",
            "  inflating: full_data/899.csv       \n",
            "  inflating: full_data/9.csv         \n",
            "  inflating: full_data/90.csv        \n",
            "  inflating: full_data/900.csv       \n",
            "  inflating: full_data/901.csv       \n",
            "  inflating: full_data/902.csv       \n",
            "  inflating: full_data/903.csv       \n",
            "  inflating: full_data/904.csv       \n",
            "  inflating: full_data/905.csv       \n",
            "  inflating: full_data/906.csv       \n",
            "  inflating: full_data/907.csv       \n",
            "  inflating: full_data/908.csv       \n",
            "  inflating: full_data/909.csv       \n",
            "  inflating: full_data/91.csv        \n",
            "  inflating: full_data/910.csv       \n",
            "  inflating: full_data/911.csv       \n",
            "  inflating: full_data/912.csv       \n",
            "  inflating: full_data/913.csv       \n",
            "  inflating: full_data/914.csv       \n",
            "  inflating: full_data/915.csv       \n",
            "  inflating: full_data/916.csv       \n",
            "  inflating: full_data/917.csv       \n",
            "  inflating: full_data/918.csv       \n",
            "  inflating: full_data/919.csv       \n",
            "  inflating: full_data/92.csv        \n",
            "  inflating: full_data/920.csv       \n",
            "  inflating: full_data/921.csv       \n",
            "  inflating: full_data/922.csv       \n",
            "  inflating: full_data/923.csv       \n",
            "  inflating: full_data/924.csv       \n",
            "  inflating: full_data/925.csv       \n",
            "  inflating: full_data/926.csv       \n",
            "  inflating: full_data/927.csv       \n",
            "  inflating: full_data/928.csv       \n",
            "  inflating: full_data/929.csv       \n",
            "  inflating: full_data/93.csv        \n",
            "  inflating: full_data/930.csv       \n",
            "  inflating: full_data/931.csv       \n",
            "  inflating: full_data/932.csv       \n",
            "  inflating: full_data/933.csv       \n",
            "  inflating: full_data/934.csv       \n",
            "  inflating: full_data/935.csv       \n",
            "  inflating: full_data/936.csv       \n",
            "  inflating: full_data/937.csv       \n",
            "  inflating: full_data/938.csv       \n",
            "  inflating: full_data/939.csv       \n",
            "  inflating: full_data/94.csv        \n",
            "  inflating: full_data/940.csv       \n",
            "  inflating: full_data/941.csv       \n",
            "  inflating: full_data/942.csv       \n",
            "  inflating: full_data/943.csv       \n",
            "  inflating: full_data/944.csv       \n",
            "  inflating: full_data/945.csv       \n",
            "  inflating: full_data/946.csv       \n",
            "  inflating: full_data/947.csv       \n",
            "  inflating: full_data/948.csv       \n",
            "  inflating: full_data/949.csv       \n",
            "  inflating: full_data/95.csv        \n",
            "  inflating: full_data/950.csv       \n",
            "  inflating: full_data/951.csv       \n",
            "  inflating: full_data/952.csv       \n",
            "  inflating: full_data/953.csv       \n",
            "  inflating: full_data/954.csv       \n",
            "  inflating: full_data/955.csv       \n",
            "  inflating: full_data/956.csv       \n",
            "  inflating: full_data/957.csv       \n",
            "  inflating: full_data/958.csv       \n",
            "  inflating: full_data/959.csv       \n",
            "  inflating: full_data/96.csv        \n",
            "  inflating: full_data/960.csv       \n",
            "  inflating: full_data/961.csv       \n",
            "  inflating: full_data/962.csv       \n",
            "  inflating: full_data/963.csv       \n",
            "  inflating: full_data/964.csv       \n",
            "  inflating: full_data/965.csv       \n",
            "  inflating: full_data/966.csv       \n",
            "  inflating: full_data/967.csv       \n",
            "  inflating: full_data/968.csv       \n",
            "  inflating: full_data/969.csv       \n",
            "  inflating: full_data/97.csv        \n",
            "  inflating: full_data/970.csv       \n",
            "  inflating: full_data/971.csv       \n",
            "  inflating: full_data/972.csv       \n",
            "  inflating: full_data/973.csv       \n",
            "  inflating: full_data/974.csv       \n",
            "  inflating: full_data/975.csv       \n",
            "  inflating: full_data/976.csv       \n",
            "  inflating: full_data/977.csv       \n",
            "  inflating: full_data/978.csv       \n",
            "  inflating: full_data/979.csv       \n",
            "  inflating: full_data/98.csv        \n",
            "  inflating: full_data/980.csv       \n",
            "  inflating: full_data/981.csv       \n",
            "  inflating: full_data/982.csv       \n",
            "  inflating: full_data/983.csv       \n",
            "  inflating: full_data/984.csv       \n",
            "  inflating: full_data/985.csv       \n",
            "  inflating: full_data/986.csv       \n",
            "  inflating: full_data/987.csv       \n",
            "  inflating: full_data/988.csv       \n",
            "  inflating: full_data/989.csv       \n",
            "  inflating: full_data/99.csv        \n",
            "  inflating: full_data/990.csv       \n",
            "  inflating: full_data/991.csv       \n",
            "  inflating: full_data/992.csv       \n",
            "  inflating: full_data/993.csv       \n",
            "  inflating: full_data/994.csv       \n",
            "  inflating: full_data/995.csv       \n",
            "  inflating: full_data/996.csv       \n",
            "  inflating: full_data/997.csv       \n",
            "  inflating: full_data/998.csv       \n",
            "  inflating: full_data/999.csv       \n",
            "  inflating: full_data/full_data.csv  \n",
            "  inflating: full_data/pH.xlsx       \n",
            "  inflating: full_data/spectra.xlsx  \n",
            "  inflating: full_data/Y_answers.xlsx  \n",
            "  inflating: full_data/Y_ions.csv    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od6r9fzyeLtz"
      },
      "source": [
        "#Customized data class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgcKUCvReGnN"
      },
      "source": [
        "# MLP_41W approach\n",
        "class FCNN_41W_Dataset(Dataset):\n",
        "    def __init__(self, annotations_file, spec_dir, transform=None, target_transform=None, sep = \",\"):\n",
        "        self.spec_labels = pd.read_csv(annotations_file, sep=',').iloc[:,1:]\n",
        "        self.spec_number = pd.read_csv(annotations_file, sep=',').iloc[:,0]\n",
        "        self.spec_dir = spec_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.spec_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.spec_labels.iloc[idx]\n",
        "        \n",
        "        sp = np.array(pd.read_csv(self.spec_dir + str(self.spec_number[idx])+'.csv').iloc[1:,1:-1], dtype='float32')\n",
        "        sp[sp<0]=0\n",
        "        spec = torch.from_numpy(sp)\n",
        "        spec = (torch.reshape(spec, (41,500))).flatten()\n",
        "        \n",
        "        \n",
        "        if self.transform:\n",
        "            spec = self.transform(spec)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return spec, torch.from_numpy(np.array(label, dtype='float32'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNoezZQyeGqH"
      },
      "source": [
        "# MLP_3W approach\n",
        "class FCNN_3W_Dataset(Dataset):\n",
        "    def __init__(self, annotations_file, spec_dir, transform=None, target_transform=None, sep = \",\"):\n",
        "        self.spec_labels = pd.read_csv(annotations_file, sep=',').iloc[:,1:]\n",
        "        self.spec_number = pd.read_csv(annotations_file, sep=',').iloc[:,0]\n",
        "        self.spec_dir = spec_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.spec_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.spec_labels.iloc[idx]\n",
        "        \n",
        "        sp = np.array(pd.read_csv(self.spec_dir + str(self.spec_number[idx])+'.csv').iloc[1:,[1,21,41]], dtype='float32')\n",
        "        sp[sp<0]=0\n",
        "        spec = torch.from_numpy(sp)\n",
        "        spec = (torch.reshape(spec, (3,500))).flatten()\n",
        "        \n",
        "        if self.transform:\n",
        "            spec = self.transform(spec)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return spec, torch.from_numpy(np.array(label, dtype='float32'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah3yyNu2eGsk"
      },
      "source": [
        "# MLP_1W approach\n",
        "class FCNN_1W_Dataset(Dataset):\n",
        "    def __init__(self, annotations_file, spec_dir, transform=None, target_transform=None, sep = \",\"):\n",
        "        self.spec_labels = pd.read_csv(annotations_file, sep=',').iloc[:,1:]\n",
        "        self.spec_number = pd.read_csv(annotations_file, sep=',').iloc[:,0]\n",
        "        self.spec_dir = spec_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.spec_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.spec_labels.iloc[idx]\n",
        "        sp = np.array(pd.read_csv(self.spec_dir + str(self.spec_number[idx])+'.csv').iloc[1:,21], dtype='float32')\n",
        "        sp[sp<0]=0\n",
        "        spec = torch.from_numpy(sp)\n",
        "        if self.transform:\n",
        "            spec = self.transform(spec)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return spec, torch.from_numpy(np.array(label, dtype='float32'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbYHYT7neGvZ"
      },
      "source": [
        "class Normalize1D:\n",
        "    def __init__(self,mean,std):\n",
        "        assert mean.shape == std.shape\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self,x):\n",
        "        # x of shape [channel, value]\n",
        "        #assert x.shape[0] == self.mean.shape[0]\n",
        "        #assert len(x.shape) == 1\n",
        "        mean = self.mean\n",
        "        std = self.std\n",
        "        return (x - std) / mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X85BvQFeGyS"
      },
      "source": [
        "#Calculate mean and std\n",
        "def mean_std(train_dataloader):\n",
        "    data = next(iter(train_dataloader))\n",
        "    mean = data[0].mean(dim=0)\n",
        "    std = data[0].std(dim=0)\n",
        "\n",
        "    return mean, std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI616aYyew-m"
      },
      "source": [
        "#Basic Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pebIH9jGe0vE"
      },
      "source": [
        "# MLP_41W approach\n",
        "class FCNN_41W(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "      \n",
        "        super().__init__() # since Python 3.0\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(20500,1000),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1000, 4)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytScxZvce01w"
      },
      "source": [
        "# MLP_3W approach\n",
        "class FCNN_3W(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "      \n",
        "        super().__init__() # since Python 3.0\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(1500,64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 4)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Mvr8FZqeG1G"
      },
      "source": [
        "# MLP_1W approach\n",
        "class FCNN_1W(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "      \n",
        "        super().__init__() # since Python 3.0\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(500,64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 4)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67LDjp1_eG3w"
      },
      "source": [
        "def reset_weights(m):\n",
        "    '''\n",
        "    Try resetting model weights to avoid\n",
        "    weight leakage.\n",
        "    '''\n",
        "    for layer in m.children():\n",
        "        if hasattr(layer, 'reset_parameters'):\n",
        "            print(f'Reset trainable parameters of layer = {layer}')\n",
        "            layer.reset_parameters()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH0Lp4NWeG6h"
      },
      "source": [
        "#Write the outputs of the network\n",
        "def write_predictions(N, model_name, split_path,dataloader,dset):\n",
        "    checkpoint = torch.load(split_path + 'model'+model_name+'.pth')\n",
        "    N.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    last_best_epoch = checkpoint['epoch']\n",
        "    loss = checkpoint['loss']\n",
        "    N.eval()\n",
        "\n",
        "    y_ae = np.zeros((1,4))\n",
        "    y_ae_true = np.zeros((1,4))\n",
        "    for specs, labels in dataloader:\n",
        "        outputs = N(specs)\n",
        "        outputs[outputs<0]=0\n",
        "        ae = outputs.detach().numpy()\n",
        "        ae_true = labels.detach().numpy()\n",
        "        #np.concatenate((y_ae, ae), axis=0)\n",
        "        y_ae = np.concatenate((y_ae, ae), axis=0)\n",
        "        y_ae_true = np.concatenate((y_ae_true, ae_true), axis=0)\n",
        "\n",
        "    a = ['Cu','Ni','Cr','NO3']\n",
        "    pd.DataFrame(y_ae).to_csv(split_path + 'Y_out_'+dset+'.csv',sep=',', header = a)\n",
        "    pd.DataFrame(y_ae_true).to_csv(split_path + 'Y_true_'+dset+'.csv',sep=',', header = a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzBv1EH2eG9V"
      },
      "source": [
        "import math\n",
        "\n",
        "def calculate_metrics(model, loader):\n",
        "    running_mae = torch.zeros(1,4)\n",
        "    running_mse = torch.zeros(1,4)\n",
        "    y_sum = torch.zeros(1,4)\n",
        "    num_examples = 0\n",
        "    total_sum_squares = torch.zeros(1,4)\n",
        "    target_mean = torch.zeros(1,4)\n",
        "\n",
        "    for specs, targets in loader:\n",
        "        y_sum += targets.sum(dim=0)\n",
        "        num_examples += specs.shape[0]\n",
        "\n",
        "    num_examples = 0\n",
        "    for specs, targets in loader:\n",
        "        preds = model(specs)\n",
        "        preds[preds<0]=0\n",
        "\n",
        "        num_examples += specs.shape[0] # batch size\n",
        "        total_sum_squares += (torch.pow(preds - y_sum, 2)).sum(dim=0)\n",
        "\n",
        "        error = torch.abs(preds - targets).sum(dim=0)\n",
        "        squared_error = ((preds - targets)*(preds - targets)).sum(dim=0)\n",
        "        running_mae += error\n",
        "        running_mse += squared_error\n",
        "  \n",
        "  \n",
        "    mae = (running_mae/num_examples).detach().numpy()\n",
        "    rmse = (torch.sqrt(running_mse/num_examples)).detach().numpy()\n",
        "    r2 = (1 - squared_error / total_sum_squares).detach().numpy()\n",
        "\n",
        "    return mae, rmse, r2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_6r3Yh1fSn2"
      },
      "source": [
        "# Prepare cross-validation datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BvXKsA-eG__"
      },
      "source": [
        "gen_path = 'full_data/'\n",
        "\n",
        "case_name = 'FCNN_1W_100_0_001_baseline' # the name of the experiment\n",
        "# case_name = model_name + stopping_criterion + learning_rate + comment\n",
        "\n",
        "cnn_1d_path = case_name+'/'\n",
        "Y = pd.read_csv(gen_path+'Y_ions.csv', sep=';')\n",
        "\n",
        "k_folds = [[42,12],[612,45],[72,172],[871,48],[52,134]] #cross-validation folds\n",
        "\n",
        "'''Write files with labels for each set (training/validation/test) within cross-validation fold - annotation files for CDS_FCNN_1W_Dataset'''\n",
        "\n",
        "for fold in k_folds:\n",
        "    split_path = cnn_1d_path+'split_'+ str(fold[0])+'_'+str(fold[1])+ '/'\n",
        "    os.makedirs(split_path, exist_ok=True)\n",
        "\n",
        "    Y_trn, Y_30 = train_test_split(Y, test_size=0.3, random_state=fold[0])\n",
        "    Y_vld, Y_tst = train_test_split(Y_30, test_size = 0.3333, random_state=fold[1])\n",
        "\n",
        "    a = ['sample_number','Cu','Ni','Cr','NO3']\n",
        "\n",
        "    pd.DataFrame(Y_trn).to_csv(split_path + 'Y_trn.csv',sep=',', index=False, header = a)\n",
        "    pd.DataFrame(Y_vld).to_csv(split_path + 'Y_vld.csv',sep=',', index=False, header = a)\n",
        "    pd.DataFrame(Y_tst).to_csv(split_path + 'Y_tst.csv',sep=',', index=False, header = a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "orLSSyO9eHC0",
        "outputId": "740fc9f2-e0e7-43a5-e215-38d657e66ca6"
      },
      "source": [
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.7 MB 8.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 180 kB 60.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 97 kB 5.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 36.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.5 MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTF5PCTjf4sc"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 977,
          "referenced_widgets": [
            "207cb99efbea4615ac6c056d4ed47db7",
            "e3abdf64aa1944d9803322f6c58fcb71",
            "33a3c7496e1641e28f43dffc9fa74dea",
            "e238fca1861942aab478ba8d401f563e",
            "e96d3c2a93164d6bb707174cc15e44ef",
            "12fde07b0ce04e2687468deb166b723f",
            "eaad389041004134ae63bf6d8e25cb63",
            "ff0cd83a2d434c4caa7b87552433416c"
          ]
        },
        "id": "gKKvG8s3eHFp",
        "outputId": "5f7e6302-3c23-4462-f98e-599bb2641af8"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "model = FCNN_1W()\n",
        "\n",
        "loss_function = torch.nn.MSELoss().cuda()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "for fold in k_folds:\n",
        "    split_path = cnn_1d_path+'split_'+ str(fold[0])+'_'+str(fold[1])+ '/'\n",
        "    \n",
        "    \n",
        "    training_data =  FCNN_1W_Dataset(split_path+'Y_trn.csv',gen_path)\n",
        "\n",
        "    train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "    mean, std = mean_std(train_dataloader)\n",
        "\n",
        "    #Data import and normalization\n",
        "    training_data =  FCNN_1W_Dataset(split_path+'Y_trn.csv', gen_path, transform= transforms.Compose([Normalize1D(mean,std)]))\n",
        "\n",
        "    validation_data =  FCNN_1W_Dataset(split_path+'Y_vld.csv', gen_path, transform= transforms.Compose([Normalize1D(mean,std)]))\n",
        "    test_data =  FCNN_1W_Dataset(split_path+'Y_tst.csv', gen_path, transform= transforms.Compose([Normalize1D(mean,std)]))\n",
        "\n",
        "    train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "    validation_dataloader = DataLoader(validation_data, batch_size=64, shuffle=True)\n",
        "    test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
        "    \n",
        "\n",
        "    for init_number in range(0,3): #Это я делаю множественную инициализацию весов сети\n",
        "\n",
        "        init_path = split_path + str(init_number)+'\\\\'\n",
        "        os.makedirs(init_path, exist_ok=True)\n",
        "\n",
        "        # Обучение\n",
        "        # критерием остановки является ошибка на валидационном наборе - останавливаемся,\n",
        "        #если в течение 100 эпох (test_stop) ошибка на валидационном наборе (val_loss) не падала\n",
        "\n",
        "        test_stop = 100 #stopping criterion\n",
        "        max_val_loss = 10000.0\n",
        "\n",
        "        wandb.init(project = case_name)\n",
        "\n",
        "        split_name = 'split_'+ str(fold[0])+'_'+str(fold[1])\n",
        "        init_name = '_' + str(init_number)\n",
        "        model_name = '_FCNN_1W'\n",
        "        wandb.run.name = split_name + init_name + model_name\n",
        "        wandb.run.save()\n",
        "\n",
        "        for epoch_step in range(0, 1000, test_stop):\n",
        "            \n",
        "            if epoch_step!=0:\n",
        "                checkpoint = torch.load(init_path + 'model'+model_name+'.pth')\n",
        "                model.load_state_dict(checkpoint['model_state_dict'])\n",
        "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "                last_best_epoch = checkpoint['epoch']\n",
        "                loss = checkpoint['loss']\n",
        "                model.train()\n",
        "                \n",
        "                if last_best_epoch + test_stop > ep:\n",
        "                    for ep in range(epoch_step, epoch_step+test_stop):\n",
        "                        for _, data in enumerate(train_dataloader, 0): # get bacth\n",
        "                            inputs, labels = data # parse batch\n",
        "                            optimizer.zero_grad() # sets the gradients of all optimized tensors to zero.\n",
        "                            outputs = model(inputs) # get outputs\n",
        "                            loss = loss_function(outputs, labels) # calculate loss\n",
        "                            loss.backward() # calculate gradients\n",
        "                            optimizer.step() # performs a single optimization step (parameter update).\n",
        "\n",
        "                        dl = 0\n",
        "                        val_loss = 0.0\n",
        "                        for specs, labels in validation_dataloader: \n",
        "                            val_loss += loss_function(model(specs),labels)\n",
        "                            dl+=1\n",
        "                        val_loss = val_loss/dl\n",
        "                        \n",
        "                        if val_loss.item() <= max_val_loss:\n",
        "                            torch.save({'epoch': ep,\n",
        "                              'model_state_dict': model.state_dict(),\n",
        "                              'optimizer_state_dict': optimizer.state_dict(),\n",
        "                              'loss': loss}, init_path + 'model'+model_name+'.pth')\n",
        "                            max_val_loss = val_loss.item()\n",
        "                        wandb.log({\"trn_loss\": loss, \"vld_loss\": val_loss})\n",
        "                else: continue    \n",
        "      \n",
        "            if epoch_step==0:\n",
        "                model.apply(reset_weights)\n",
        "\n",
        "                for ep in range(epoch_step, test_stop):\n",
        "                    for _, data in enumerate(train_dataloader, 0): # get bacth\n",
        "                        inputs, labels = data # parse batch\n",
        "                        optimizer.zero_grad() # sets the gradients of all optimized tensors to zero.\n",
        "                        outputs = model(inputs) # get outputs\n",
        "                        loss = loss_function(outputs, labels) # calculate loss\n",
        "                        loss.backward() # calculate gradients\n",
        "                        optimizer.step() # performs a single optimization step (parameter update).\n",
        "\n",
        "                    dl = 0\n",
        "                    val_loss = 0.0\n",
        "                    for specs, labels in validation_dataloader:\n",
        "                        val_loss += loss_function(model(specs),labels)\n",
        "                        dl+=1\n",
        "                    val_loss = val_loss/dl\n",
        "\n",
        "                    if val_loss.item() <= max_val_loss:\n",
        "                        torch.save({'epoch': ep,\n",
        "                          'model_state_dict': model.state_dict(),\n",
        "                          'optimizer_state_dict': optimizer.state_dict(),\n",
        "                          'loss': loss}, init_path + 'model'+model_name+'.pth')\n",
        "                        max_val_loss = val_loss.item()\n",
        "                    wandb.log({\"trn_loss\": loss, \"vld_loss\": val_loss})\n",
        "\n",
        "        trn_metrics = calculate_metrics(model, train_dataloader)\n",
        "        vld_metrics = calculate_metrics(model, validation_dataloader)\n",
        "        tst_metrics = calculate_metrics(model, test_dataloader)\n",
        "\n",
        "        wandb.log({\"trn_mae\": trn_metrics[0].sum()/4, \"trn_rmse\": trn_metrics[1].sum()/4,\"trn_r2\": trn_metrics[2].sum()/4})\n",
        "        wandb.log({\"vld_mae\": vld_metrics[0].sum()/4, \"vld_rmse\": vld_metrics[1].sum()/4,\"vld_r2\": vld_metrics[2].sum()/4})\n",
        "        wandb.log({\"tst_mae\": tst_metrics[0].sum()/4, \"tst_rmse\": tst_metrics[1].sum()/4,\"tst_r2\": tst_metrics[2].sum()/4})\n",
        "        wandb.log({\"epoch\": ep})\n",
        "\n",
        "        wandb.finish()\n",
        "\n",
        "        write_predictions(model, model_name, init_path, train_dataloader, dset = 'trn')\n",
        "        write_predictions(model, model_name, init_path, validation_dataloader, dset ='vld')\n",
        "        write_predictions(model, model_name, init_path, test_dataloader, dset ='tst')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moe_sarmanova\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/oe_sarmanova/FCNN_1W_100_0_001_baseline/runs/1vyrkxpt\" target=\"_blank\">deft-deluge-59</a></strong> to <a href=\"https://wandb.ai/oe_sarmanova/FCNN_1W_100_0_001_baseline\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reset trainable parameters of layer = Linear(in_features=500, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=4, bias=True)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 298... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "207cb99efbea4615ac6c056d4ed47db7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
              "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>trn_loss</td><td>█▄▂▂▁▂</td></tr><tr><td>trn_mae</td><td>▁</td></tr><tr><td>trn_r2</td><td>▁</td></tr><tr><td>trn_rmse</td><td>▁</td></tr><tr><td>tst_mae</td><td>▁</td></tr><tr><td>tst_r2</td><td>▁</td></tr><tr><td>tst_rmse</td><td>▁</td></tr><tr><td>vld_loss</td><td>█▃▂▁▁▁</td></tr><tr><td>vld_mae</td><td>▁</td></tr><tr><td>vld_r2</td><td>▁</td></tr><tr><td>vld_rmse</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
              "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>trn_loss</td><td>26.30464</td></tr><tr><td>trn_mae</td><td>3.01367</td></tr><tr><td>trn_r2</td><td>1.0</td></tr><tr><td>trn_rmse</td><td>3.67821</td></tr><tr><td>tst_mae</td><td>3.07872</td></tr><tr><td>tst_r2</td><td>0.99998</td></tr><tr><td>tst_rmse</td><td>3.68745</td></tr><tr><td>vld_loss</td><td>24.73696</td></tr><tr><td>vld_mae</td><td>3.16646</td></tr><tr><td>vld_r2</td><td>1.0</td></tr><tr><td>vld_rmse</td><td>3.88986</td></tr></table>\n",
              "</div></div>\n",
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
              "<br/>Synced <strong style=\"color:#cdcd00\">deft-deluge-59</strong>: <a href=\"https://wandb.ai/oe_sarmanova/FCNN_1W_100_0_001_baseline/runs/1vyrkxpt\" target=\"_blank\">https://wandb.ai/oe_sarmanova/FCNN_1W_100_0_001_baseline/runs/1vyrkxpt</a><br/>\n",
              "Find logs at: <code>./wandb/run-20211207_104836-1vyrkxpt/logs</code><br/>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/oe_sarmanova/FCNN_1W_100_0_001_baseline/runs/12deqmzp\" target=\"_blank\">peachy-butterfly-60</a></strong> to <a href=\"https://wandb.ai/oe_sarmanova/FCNN_1W_100_0_001_baseline\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reset trainable parameters of layer = Linear(in_features=500, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=4, bias=True)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-1b69fb9586bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlast_best_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtest_stop\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_step\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtest_stop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# get bacth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m                             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;31m# parse batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sets the gradients of all optimized tensors to zero.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-9512ff95ecaf>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0msp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec_number\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0msp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mapply_if_callable\u001b[0;34m(maybe_callable, obj, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \"\"\"\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP_oiYaNeHLA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YR9-Qa-8eHNx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W14hmNZreHQn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8W0_FI7eHTe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC31SLMZeHWS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}